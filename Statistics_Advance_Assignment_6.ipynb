{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+4TXw2HMSw/+G068FALm7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameermdanwer/python-assignment-/blob/main/Statistics_Advance_Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
        "the validity of the results.\n",
        "\n",
        "ANOVA (Analysis of Variance) is a statistical technique used to compare the means of three or more groups to determine if at least one group mean is statistically significantly different from others. However, like all statistical techniques, ANOVA is built upon several critical assumptions. If these assumptions are violated, the validity of the ANOVA results can be compromised. Below are the primary assumptions of ANOVA, along with examples of violations and their potential impacts:\n",
        "\n",
        "# 1. Independence of Observations\n",
        "Assumption: Observations within each group must be independent of one another. This means that the data collected from one subject or group should not influence or be related to the data collected from another subject or group.\n",
        "\n",
        "Examples of Violations:\n",
        "\n",
        "* Repeated Measures: If the same subjects are measured multiple times (e.g., before and after treatment), the independence assumption is violated.\n",
        "* Cluster Sampling: If samples are taken from naturally occurring groups (like classrooms), individuals within the same group may affect each other’s responses.\n",
        "* Impact: If independence is violated, the results of ANOVA might lead to inflated Type I error rates (incorrectly rejecting the null hypothesis), as the true variability among the groups may be underestimated.\n",
        "\n",
        "# 2. Normality of Residuals\n",
        "Assumption: The residuals (the differences between observed and predicted values) should be normally distributed. While it’s not necessary for the original data to be normally distributed, the distribution of residuals should be normal, especially for small sample sizes.\n",
        "\n",
        "Examples of Violations:\n",
        "\n",
        "* Skewed Data: If the data is heavily skewed or contains outliers, the residuals will not follow a normal distribution.\n",
        "* Transformation Issues: Using inappropriate transformations for variable types (like other than log or square root for right-skewed data) can maintain or worsen normality issues.\n",
        "* Impact: Violation of the normality assumption can lead to inaccurate p-values, resulting in a higher likelihood of Type I or Type II errors (failing to reject the null hypothesis when it is false).\n",
        "\n",
        "# 3. Homogeneity of Variances (Homoscedasticity)\n",
        "Assumption: The variances among the groups being compared should be roughly equal. This assumption can be assessed using tests like Levene's test or Bartlett's test.\n",
        "\n",
        "Examples of Violations:\n",
        "\n",
        "* Inconsistent Variability: If one group has much more variability in its data compared to another (for instance, group A has a variance of 2 and group B has a variance of 30), this leads to heteroscedasticity.\n",
        "* Different Measurement Techniques: Using different methods to measure the same phenomenon could lead to different variances between groups.\n",
        "* Impact: If the variances are significantly different (heteroscedasticity), it can lead to biased F-ratios and thus affect the validity of the ANOVA results. It may, for example, lead to underestimating or overestimating the significance of group distinctions.\n",
        "\n",
        "# 4. Random Sampling\n",
        "* Assumption: The samples must be drawn randomly from the populations. This ensures that the sample is representative of the population.\n",
        "\n",
        "Examples of Violations:\n",
        "\n",
        "* Convenience Sampling: If the sample is taken from easily accessible subjects rather than a random selection, it may not represent the population well.\n",
        "* Self-selection: Participants may choose whether or not to partake in a study, leading to biased groups.\n",
        "* Impact: Non-random sampling could lead to systematic biases in results, impacting the generalizability of the findings and potentially misleading conclusions about differences between groups."
      ],
      "metadata": {
        "id": "yYaW7lUijLFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
        "\n",
        "ANOVA, or Analysis of Variance, is a statistical method used to compare the means of three or more groups to determine if at least one group differs significantly from the others. There are three primary types of ANOVA, each suited for different experimental designs and situations:\n",
        "\n",
        "# 1. One-Way ANOVA\n",
        "Definition:\n",
        "One-way ANOVA is used to compare the means of three or more independent groups that differ on one independent variable (factor). It tests the hypothesis that at least one of the group means is different from the others.\n",
        "\n",
        "When to Use:\n",
        "\n",
        "* When you have one categorical independent variable with two or more levels (groups) and a continuous dependent variable.\n",
        "* For example, comparing the test scores among students from three different schools to see if the school affects performance.\n",
        "* Situations where you want to test the effect of a single treatment or condition (e.g., comparing three different diets on weight loss).\n",
        "Example:\n",
        "A researcher wants to examine whether three different teaching methods (Lecture, Interactive, and Blended) have different effects on student performance.\n",
        "\n",
        "# 2. Two-Way ANOVA\n",
        "Definition:\n",
        "Two-way ANOVA is used to examine the influence of two independent categorical variables (factors) on a continuous dependent variable, as well as to investigate if there is an interaction effect between the two factors.\n",
        "\n",
        "When to Use:\n",
        "\n",
        "* When analyzing the effects of two factors simultaneously while also assessing their interaction.\n",
        "* For instance, evaluating the effects of both diet (e.g., Low-Carb vs. Regular) and exercise (e.g., Yes vs. No) on weight loss.\n",
        "Example:\n",
        "A study examines how two factors—type of fertilizer (Organic, Synthetic) and amount of sunlight (Full Sun, Partial Sun)—affect plant growth.\n",
        "\n",
        "# 3. Repeated Measures ANOVA (within-subjects ANOVA)\n",
        "Definition:\n",
        "Repeated measures ANOVA is used when the same subjects are measured multiple times under different conditions or at different time points. This type accounts for the fact that measurements are not independent due to repeated testing of the same participants.\n",
        "\n",
        "When to Use:\n",
        "\n",
        "* When the same participants are subjected to different conditions (e.g., measuring their performance under different drugs, treatments, or time points).\n",
        "* Situations where you want to analyze how a dependent variable changes over time or across different conditions while controlling for inter-subject variability.\n",
        "Example:\n",
        "A psychologist tests the stress levels of the same group of participants at three different times: before a stressful event, during the event, and after the event.\n"
      ],
      "metadata": {
        "id": "WSDg1OJZkMHZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
        "\n",
        " Partitioning of variance in ANOVA is a critical concept that refers to the process of breaking down the total variance observed in a dataset into its components. This breakdown helps researchers understand the sources of variability in the data and allows for meaningful comparisons among groups. The partitioning of variance entails distinguishing between the variability that can be attributed to the different groups being studied and the variability that arises from random error or individual differences within those groups.\n",
        "\n",
        "# Understanding the Components of Variance\n",
        "In ANOVA, the total variance in the dependent variable can be partitioned into two main components:\n",
        "\n",
        "1. Between-Group Variance (Explained Variance):\n",
        "This is the variance that is attributed to the differences between the means of the groups. It reflects how much the group means vary from the overall mean of all observations. A larger between-group variance indicates that the groups are more distinct or that the treatment or factor has a significant effect.\n",
        "\n",
        "* Mathematically: ( \\text{Between-Group Variance} = \\sum_{i=1}^k n_i (\\bar{X}_i - \\bar{X})^2 ) where ( k ) is the number of groups, ( n_i ) is the sample size of the i-th group, ( \\bar{X}_i ) is the mean of the i-th group, and ( \\bar{X} ) is the overall mean.\n",
        "2. Within-Group Variance (Unexplained Variance):\n",
        "\n",
        "This is the variance within each group that is not explained by the differences between the group means. It reflects the individual differences or random error within groups. A higher within-group variance indicates more variability among the individuals within the same group.\n",
        "\n",
        "* Mathematically: ( \\text{Within-Group Variance} = \\sum_{i=1}^k \\sum_{j=1}^{n_i} (X_{ij} - \\bar{X}i)^2 ) where ( X{ij} ) represents the j-th observation in group i.\n",
        "The Total Variance can then be expressed as:\n",
        "[ \\text{Total Variance} = \\text{Between-Group Variance} + \\text{Within-Group Variance} ]\n",
        "\n",
        "# Importance of Understanding Partitioning of Variance\n",
        "1. Assessment of Treatment Effects:\n",
        "By understanding how variance is partitioned, researchers can determine whether the groups are significantly different from each other. If the between-group variance is significantly larger than the within-group variance, this suggests that the treatment or categorical factor has a meaningful impact.\n",
        "\n",
        "2. Calculation of the F-ratio:\n",
        "The partitioning of variance is essential for calculating the F-statistic, which is the ratio of between-group variance to within-group variance:\n",
        "[\n",
        "F = \\frac{\\text{Between-Group Variance}}{\\text{Within-Group Variance}}\n",
        "]\n",
        "A larger F-statistic indicates a greater likelihood that the group means are different due to the effects of the independent variable rather than random chance.\n",
        "\n",
        "3. Guiding Experimental Design:\n",
        "Understanding how variance is accounted for can inform researchers about how to structure their experiments. For instance, if the within-group variance is high, steps can be taken to control extraneous variables or increase sample sizes to improve the precision of estimates.\n",
        "\n",
        "4. Interpreting Results:\n",
        "Researchers need to interpret the results of ANOVA correctly. Recognizing where the variance is coming from (between versus within groups) allows for better understanding of the context of significant findings, including the actual impact of a treatment or condition.\n",
        "\n",
        "5. Model Diagnostics and Assumptions:\n",
        "The partitioning of variance can also provide insights into the assumptions underlying ANOVA, such as normality and homogeneity of variances. Researchers can check whether the variance structures meet the assumptions required to apply ANOVA and can take corrective actions if necessary."
      ],
      "metadata": {
        "id": "XsgmDow9lCLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
        "sum of squares (SSR) in a one-way ANOVA using Python?\n",
        "\n",
        "In a one-way ANOVA, you typically deal with three important sums of squares:\n",
        "\n",
        "1. Total Sum of Squares (SST): This measures the total variability in the dependent variable.\n",
        "2. Explained Sum of Squares (SSE): This measures the variability that can be explained by the model (i.e., the differences between the group means).\n",
        "3. Residual Sum of Squares (SSR): This measures the variability that cannot be explained by the model (i.e., the variability within the groups).\n",
        "# Definitions\n",
        "* Total Sum of Squares (SST):\n",
        "[ \\text{SST} = \\sum_{i=1}^{N} (X_i - \\bar{X})^2 ]\n",
        "where ( X_i ) is each individual observation, ( N ) is the total number of observations, and ( \\bar{X} ) is the overall mean of all observations.\n",
        "\n",
        "* Explained Sum of Squares (SSE):\n",
        "[ \\text{SSE} = \\sum_{j=1}^{k} n_j (\\bar{X}_j - \\bar{X})^2 ]\n",
        "where ( k ) is the number of groups, ( n_j ) is the number of observations in group ( j ), and ( \\bar{X}_j ) is the mean of group ( j ).\n",
        "\n",
        "* Residual Sum of Squares (SSR):\n",
        "[ \\text{SSR} = \\sum_{j=1}^{k} \\sum_{i=1}^{n_j} (X_{ij} - \\bar{X}j)^2 ]\n",
        "where ( X{ij} ) is the i-th observation in group ( j ) and ( \\bar{X}_j ) is the mean of group ( j ).\n"
      ],
      "metadata": {
        "id": "GKYUvnFQl-1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
        "    'values': [5, 7, 6, 8, 9, 7, 10, 11, 10]\n",
        "}\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate overall mean (X-bar)\n",
        "overall_mean = np.mean(df['values'])\n",
        "\n",
        "# Calculate Total Sum of Squares (SST)\n",
        "SST = np.sum((df['values'] - overall_mean) ** 2)\n",
        "\n",
        "# Calculate group means\n",
        "group_means = df.groupby('group')['values'].mean()\n",
        "\n",
        "# Calculate Explained Sum of Squares (SSE)\n",
        "n = df['group'].value_counts()  # Number of observations per group\n",
        "SSE = np.sum(n * (group_means - overall_mean) ** 2)\n",
        "\n",
        "# Calculate Residual Sum of Squares (SSR)\n",
        "SSR = SST - SSE\n",
        "\n",
        "# Print results\n",
        "print(f'Total Sum of Squares (SST): {SST:.2f}')\n",
        "print(f'Explained Sum of Squares (SSE): {SSE:.2f}')\n",
        "print(f'Residual Sum of Squares (SSR): {SSR:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tADZjQ17mQms",
        "outputId": "55a3da6b-c0a0-4da6-d97c-f017ede386ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sum of Squares (SST): 32.89\n",
            "Explained Sum of Squares (SSE): 28.22\n",
            "Residual Sum of Squares (SSR): 4.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
        "\n",
        "In a two-way ANOVA, you assess the impact of two independent categorical variables (also known as factors) on a continuous dependent variable. In addition to evaluating the individual effects of each factor (main effects), you can also examine whether there is an interaction between the two factors (interaction effect).\n",
        "\n",
        "# Steps to Calculate Main Effects and Interaction Effects in Python\n",
        "To perform a two-way ANOVA and calculate the main effects and interaction effects, you can use the statsmodels library in Python. Below is a step-by-step example using a sample dataset."
      ],
      "metadata": {
        "id": "Pw3CIIRAmpKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Sample data setup\n",
        "data = {\n",
        "    'FactorA': ['A1', 'A1', 'A1', 'A2', 'A2', 'A2', 'A1', 'A1', 'A1', 'A2', 'A2', 'A2'],\n",
        "    'FactorB': ['B1', 'B1', 'B1', 'B1', 'B1', 'B1', 'B2', 'B2', 'B2', 'B2', 'B2', 'B2'],\n",
        "    'Response': [5, 6, 7, 8, 9, 6, 7, 8, 9, 10, 11, 10]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOQCfZ_-n1wa",
        "outputId": "e4eac29d-0ad8-4204-ddce-5a6920d6b1f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   FactorA FactorB  Response\n",
            "0       A1      B1         5\n",
            "1       A1      B1         6\n",
            "2       A1      B1         7\n",
            "3       A2      B1         8\n",
            "4       A2      B1         9\n",
            "5       A2      B1         6\n",
            "6       A1      B2         7\n",
            "7       A1      B2         8\n",
            "8       A1      B2         9\n",
            "9       A2      B2        10\n",
            "10      A2      B2        11\n",
            "11      A2      B2        10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Two-Way ANOVA\n",
        "1. Define the Model You can define the ANOVA model using the formula syntax where Response is the dependent variable, and FactorA, FactorB, and their interaction are independent variables."
      ],
      "metadata": {
        "id": "_Dr9igt-n85v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = ols('Response ~ C(FactorA) * C(FactorB)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)  # Type II ANOVA\n",
        "\n",
        "print(anova_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSnAjL03oDJ1",
        "outputId": "0a589282-66a2-481b-b75e-386f4d4e6d8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          sum_sq   df          F    PR(>F)\n",
            "C(FactorA)             12.000000  1.0  10.285714  0.012478\n",
            "C(FactorB)             16.333333  1.0  14.000000  0.005692\n",
            "C(FactorA):C(FactorB)   0.333333  1.0   0.285714  0.607511\n",
            "Residual                9.333333  8.0        NaN       NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
        "What can you conclude about the differences between the groups, and how would you interpret these\n",
        "results?\n",
        "\n",
        "When conducting a one-way ANOVA, you are generally testing the null hypothesis that there are no differences in the means of the groups being compared. In your case, you obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how you can interpret these results:\n",
        "\n",
        "# Interpretation of the F-statistic\n",
        "1. F-statistic: The F-statistic provides a measure of the ratio of the variance between the groups to the variance within the groups. A higher F-statistic suggests that a larger proportion of the variance is attributable to the group differences rather than to random chance. In your case, an F-statistic of 5.23 indicates that there is some evidence suggesting that the means of the different groups are not all equal.\n",
        "\n",
        "# Interpretation of the p-value\n",
        "2. P-value: The p-value indicates the probability of observing an F-statistic as extreme as (or more extreme than) the one obtained (5.23) under the null hypothesis. A p-value of 0.02 means that there is a 2% probability of obtaining such an F-statistic if the null hypothesis were true (i.e., if there were no actual differences between the group means).\n",
        "# Conclusion Based on the Results\n",
        "Given that the p-value (0.02) is less than the common alpha level of 0.05, you would reject the null hypothesis. This suggests that there is a statistically significant difference between at least one pair of group means.\n",
        "\n",
        "Here's a structured conclusion:\n",
        "\n",
        "* Statistical Significance: Since p < 0.05, we conclude that there is evidence to suggest that at least one group mean is significantly different from the others.\n",
        "\n",
        "* Practical Interpretation: While the ANOVA tells us that not all group means are equal, it does not specify which groups are different from each other. To find out which specific groups differ, a post hoc test (like Tukey's HSD, Bonferroni, or Scheffé test) would need to be conducted.\n"
      ],
      "metadata": {
        "id": "kBNdLpmzoE_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
        "consequences of using different methods to handle missing data?\n",
        "\n",
        "Handling missing data in repeated measures ANOVA is crucial because it can impact the validity and interpretation of your results. Here are various methods to address missing data and the potential consequences associated with each approach:\n",
        "\n",
        "# Methods for Handling Missing Data\n",
        "1. Listwise Deletion (Complete Case Analysis):\n",
        "\n",
        "* Description: Only the subjects with complete data across all time points are included in the analysis.\n",
        "* Consequences:\n",
        "* Pros: Simple to implement and interpret.\n",
        "* Cons: This method can lead to significant loss of data, particularly if many subjects have missing values. If the missing data are not missing completely at random (MCAR), it can lead to biased estimates and reduced generalizability.\n",
        "2. Pairwise Deletion:\n",
        "\n",
        "* Description: Analyses are performed using all available data for each pair of groups being compared, allowing for different numbers of observations across comparisons.\n",
        "* Consequences:\n",
        "* Pros: Makes use of more data than listwise deletion.\n",
        "* Cons: Can lead to inconsistencies in the sample size across comparisons and inflated Type I error rates. Results may also be less reliable because different subsets of data are used.\n",
        "3. Mean Imputation:\n",
        "\n",
        "* Description: Missing values for each participant are replaced with the mean value of that participant's other measurements.\n",
        "* Consequences:\n",
        "* Pros: Easy to implement and preserves sample size.\n",
        "* Cons: Reduces variability in the dataset, can bias results due to artificially reducing standard deviations, and fails to consider the correlations between repeated measures.\n",
        "4. Last Observation Carried Forward (LOCF):\n",
        "\n",
        "* Description: The last observed value for each participant is used to fill in missing subsequent values.\n",
        "* Consequences:\n",
        "* Pros: Preserves the sample size and is straightforward to implement.\n",
        "* Cons: Assumes that the last observation remains valid, which may not be true, especially in longitudinal data. It can lead to biased results and artificially stabilize trends.\n",
        "5. Multiple Imputation:\n",
        "\n",
        "* Description: Missing values are estimated multiple times to create several plausible datasets, which are then analyzed separately, and results are pooled.\n",
        "* Consequences:\n",
        "* Pros: Provides a statistically principled way of handling missing data, accounts for uncertainty, and is often seen as the best practice when dealing with missing data.\n",
        "* Cons: More complex to implement and requires assumptions about the distribution of the missing data. The quality of imputations depends on the model specified.\n",
        "6. Mixed-Effects Models (also called  Hierarchical Models):\n",
        "\n",
        "* Description: These models allow for missing data points and provide estimates that account for the correlation between repeated measures.\n",
        "* Consequences:\n",
        "* Pros: Flexible and can handle unbalanced data. It allows the inclusion of all available data and can give accurate estimates of effects.\n",
        "* Cons: Complexity in model specification and interpretation, and requires careful consideration of random effects.\n",
        "\n",
        "# Potential Consequences of Different Methods\n",
        "\n",
        "* Bias: Techniques like mean imputation and LOCF can introduce bias in the estimates, especially if the data are not MCAR.\n",
        "* Loss of Power: Methods that involve deletion (listwise or pairwise) can significantly reduce the sample size and thus the power of the analysis.\n",
        "* Increased Type I Error: Inconsistent sample sizes across comparisons (as in pairwise deletion) can lead to increased Type I error rates.\n",
        "* Reduced Variability: Imputation methods can reduce variability in the dataset, affecting the estimates of means and variances.\n",
        "* Generalizability: The method chosen can affect the generalizability of findings; for example, if data are systematically missing for certain groups, results may not reflect the true population."
      ],
      "metadata": {
        "id": "EGomMjuSoqgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
        "an example of a situation where a post-hoc test might be necessary.\n",
        "\n",
        "Post-hoc tests are used after conducting an ANOVA to determine which specific group means are significantly different from each other. They are necessary when the ANOVA indicates that there are significant differences among the groups, but does not specify where those differences lie. Here are some common post-hoc tests along with their typical applications:\n",
        "\n",
        "# Common Post-Hoc Tests\n",
        "1. Tukey's Honestly Significant Difference (HSD) Test:\n",
        "\n",
        "* Use: Tukey's HSD is used when you want to compare all possible pairs of group means with a control of the family-wise error rate.\n",
        "* When to Use: It is best suited for equal sample sizes across groups, although it can handle unequal sample sizes to some extent.\n",
        "* Example: Comparing the effectiveness of three different teaching methods on student performance where you have three groups (e.g., Method A, Method B, Method C). If the ANOVA shows significant differences among the groups, Tukey's HSD can determine which methods differ from each other.\n",
        "2. Bonferroni Correction:\n",
        "\n",
        "* Use: The Bonferroni adjustment is straightforward and involves dividing the significance level (alpha) by the number of tests being conducted. It is applied when you want to keep the family-wise error rate under control.\n",
        "* When to Use: It is useful when conducting a small number of comparisons.\n",
        "* Example: If you want to compare four different diets on weight loss, and the ANOVA indicates significant differences, you may perform pairwise comparisons with the Bonferroni approach to see which specific diets (e.g., Diet 1 vs. Diet 2) differ, adjusting the alpha level to account for the multiple comparisons.\n",
        "3. Scheffé's Test:\n",
        "\n",
        "* Use: Allows for comparison of groups in a more flexible way, including contrasts involving multiple groups.\n",
        "* When to Use: It is appropriate when the number of groups is small or when the focus is on specific contrasts rather than pairwise differences.\n",
        "* Example: Useful in studies where one might want to compare the means of several treatments against a control treatment, and you have unequal sample sizes or non-normal distributions.\n",
        "4. Dunnett's Test:\n",
        "\n",
        "* Use: Specifically compares each experimental group with a control group.\n",
        "* When to Use: When you have multiple treatment groups and want to assess them against a particular control group only.\n",
        "* Example: In a clinical trial testing new medications for treating a disease, if you want to compare the effectiveness of three new drugs against a placebo group, you would use Dunnett's Test.\n",
        "5. Newman-Keuls Test:\n",
        "\n",
        "* Use: A stepwise test that compares means in a hierarchical manner. It is generally less conservative than Tukey's HSD.\n",
        "* When to Use: When you have a larger number of groups and the most significant contrasts of means are of interest.\n",
        "* Example: In a psychological study assessing stress reduction across various therapies, the Newman-Keuls test can help identify therapy pairs that have differing effects on stress levels.\n",
        "\n",
        "# Example Situation Where a Post-Hoc Test Might Be Necessary\n",
        "\n",
        "Suppose you conduct an experiment to evaluate the impact of four different fertilizers (Fertilizer A, Fertilizer B, Fertilizer C, and Fertilizer D) on plant growth. After performing a one-way ANOVA, you find a significant F-statistic indicating that at least one of the fertilizers leads to different growth levels among the plants.\n",
        "\n",
        "Since the ANOVA does not specify which fertilizers differ, you proceed with a post-hoc test, such as Tukey's HSD. This will allow you to conduct pairwise comparisons between the fertilizers to determine whether the mean plant growth with Fertilizer A is different from that of Fertilizer B, C, and D, and so on.\n",
        "\n",
        "In summary, post-hoc tests are essential tools following ANOVA when you find significant differences among group means and need to identify where those differences lie. The choice of post-hoc test depends on your study design, th\n"
      ],
      "metadata": {
        "id": "eZb4U3FpqCNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
        "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
        "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
        "Report the F-statistic and p-value, and interpret the results.\n",
        "\n",
        "To conduct a one-way ANOVA to compare the mean weight loss of three diets (A, B, and C) in Python, we first need to generate some sample data (or you can input your actual weight loss data). Below is a complete Python code snippet that simulates data for this scenario, performs the one-way ANOVA, and interprets the results using the scipy and statsmodels libraries.\n",
        "\n",
        "Python Code"
      ],
      "metadata": {
        "id": "BWRvhKztrJnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Simulating weight loss data for three diets\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "# Sample data: assume the weight loss (in pounds) for each diet\n",
        "diet_a = np.random.normal(loc=10, scale=2, size=20)  # Diet A\n",
        "diet_b = np.random.normal(loc=12, scale=2, size=20)  # Diet B\n",
        "diet_c = np.random.normal(loc=15, scale=2, size=20)  # Diet C\n",
        "\n",
        "# Combine data into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'WeightLoss': np.concatenate([diet_a, diet_b, diet_c]),\n",
        "    'Diet': ['A'] * 20 + ['B'] * 20 + ['C'] * 20\n",
        "})\n",
        "\n",
        "# Conducting one-way ANOVA\n",
        "model = ols('WeightLoss ~ C(Diet)', data=data).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Extracting F-statistic and p-value\n",
        "f_statistic = anova_table['F'][0]\n",
        "p_value = anova_table['PR(>F)'][0]\n",
        "\n",
        "# Display the results\n",
        "print(\"ANOVA Results:\")\n",
        "print(f\"F-statistic: {f_statistic:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpreting the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis. There are significant differences in mean weight loss among the diets.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. No significant differences in mean weight loss among the diets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npxa5X3ure96",
        "outputId": "7137615e-b422-4251-d18b-4d019d3521fb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANOVA Results:\n",
            "F-statistic: 42.7976\n",
            "p-value: 0.0000\n",
            "Result: Reject the null hypothesis. There are significant differences in mean weight loss among the diets.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-ce2aa6a513d7>:26: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  f_statistic = anova_table['F'][0]\n",
            "<ipython-input-4-ce2aa6a513d7>:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  p_value = anova_table['PR(>F)'][0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
        "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
        "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
        "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
        "interaction effects between the software programs and employee experience level (novice vs.\n",
        "experienced). Report the F-statistics and p-values, and interpret the results.\n",
        "\n",
        "To conduct a two-way ANOVA in Python that examines the effects of software programs (Program A, Program B, Program C) and employee experience levels (novice vs. experienced) on the time taken to complete a task, we need to create a dataset that includes both factors. Below is a complete Python code snippet that simulates such data, carries out the two-way ANOVA, and provides interpretations of the results.\n",
        "\n",
        "Python Code"
      ],
      "metadata": {
        "id": "Ovra7WBJryWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulating the data\n",
        "programs = ['A', 'B', 'C']\n",
        "experience_levels = ['Novice', 'Experienced']\n",
        "\n",
        "# Generating sample data\n",
        "data = []\n",
        "for program in programs:\n",
        "    for experience in experience_levels:\n",
        "        if experience == 'Novice':\n",
        "            # Random times for novices (mean = 30, std = 5)\n",
        "            times = np.random.normal(loc=30, scale=5, size=15)\n",
        "        else:\n",
        "            # Random times for experienced (mean = 25, std = 5)\n",
        "            times = np.random.normal(loc=25, scale=5, size=15)\n",
        "\n",
        "        # Append to data list\n",
        "        for time in times:\n",
        "            data.append({'Time': time, 'Program': program, 'Experience': experience})\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Conducting two-way ANOVA\n",
        "model = ols('Time ~ C(Program) * C(Experience)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "# Extracting F-statistics and p-values\n",
        "f_stats = anova_table['F']\n",
        "p_values = anova_table['PR(>F)']\n",
        "\n",
        "# Display the results\n",
        "print(\"Two-Way ANOVA Results:\")\n",
        "print(anova_table)\n",
        "\n",
        "# Interpretation of results\n",
        "alpha = 0.05\n",
        "for i in range(len(anova_table)):\n",
        "    if p_values[i] < alpha:\n",
        "        print(f\"Result for {anova_table.index[i]}: Reject the null hypothesis. Significant effect.\")\n",
        "    else:\n",
        "        print(f\"Result for {anova_table.index[i]}: Fail to reject the null hypothesis. No significant effect.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVuRQY9fr7WS",
        "outputId": "af0a5781-70a2-4cd2-b652-b804f6028453"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two-Way ANOVA Results:\n",
            "                               sum_sq    df          F    PR(>F)\n",
            "C(Program)                  15.717327   2.0   0.350798  0.705152\n",
            "C(Experience)              622.680166   1.0  27.795447  0.000001\n",
            "C(Program):C(Experience)    45.903396   2.0   1.024527  0.363407\n",
            "Residual                  1881.787816  84.0        NaN       NaN\n",
            "Result for C(Program): Fail to reject the null hypothesis. No significant effect.\n",
            "Result for C(Experience): Reject the null hypothesis. Significant effect.\n",
            "Result for C(Program):C(Experience): Fail to reject the null hypothesis. No significant effect.\n",
            "Result for Residual: Fail to reject the null hypothesis. No significant effect.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3f4968c3b043>:46: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  if p_values[i] < alpha:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
        "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
        "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
        "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
        "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
        "group(s) differ significantly from each other.\n",
        "\n",
        "To conduct a two-sample t-test comparing test scores between a control group (traditional teaching method) and an experimental group (new teaching method), we can use Python libraries such as scipy for the t-test and statsmodels or pingouin for post-hoc testing if needed. Below is a complete Python code snippet that simulates student test scores for both groups, performs the t-test, and interprets the results. Additionally, if the results are significant, we will use a post-hoc test for further analysis."
      ],
      "metadata": {
        "id": "Dq0DIw4tr-MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import pingouin as pg  # For post-hoc testing (if needed)\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulating test scores for the two groups\n",
        "# Control group (traditional teaching method)\n",
        "control_group = np.random.normal(loc=75, scale=10, size=50)  # mean = 75, std = 10, n = 50\n",
        "\n",
        "# Experimental group (new teaching method)\n",
        "experimental_group = np.random.normal(loc=80, scale=10, size=50)  # mean = 80, std = 10, n = 50\n",
        "\n",
        "# Conducting a two-sample t-test\n",
        "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
        "\n",
        "# Display the t-test results\n",
        "print(\"Two-Sample T-Test Results:\")\n",
        "print(f\"T-statistic: {t_statistic:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Result: Reject the null hypothesis. There is a significant difference in test scores.\")\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. No significant difference in test scores.\")\n",
        "\n",
        "# If results are significant, perform a post-hoc test (e.g., independent samples)\n",
        "# Not commonly needed after t-test since only two groups are compared, but included for completeness.\n",
        "if p_value < alpha:\n",
        "    # Concatenate both groups for post-hoc\n",
        "    scores = np.concatenate([control_group, experimental_group])\n",
        "    group_labels = ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)\n",
        "\n",
        "    post_hoc_df = pd.DataFrame({'Scores': scores, 'Group': group_labels})\n",
        "\n",
        "    # Conducting post-hoc test (although it's not generally necessary for only two groups)\n",
        "    post_hoc_results = pg.pairwise_ttests(data=post_hoc_df, dv='Scores', between='Group')\n",
        "    print(\"\\nPost-hoc Test Results:\")\n",
        "    print(post_hoc_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "hDo1Tv7bsNJu",
        "outputId": "d2e8f0ff-371f-4adf-8e19-f08da4d5f763"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pingouin'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-79662c99c012>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpingouin\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpg\u001b[0m  \u001b[0;31m# For post-hoc testing (if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Set a random seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pingouin'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
        "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
        "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
        "\n",
        "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
        "hoc test to determine which store(s) differ significantly from each other.\n",
        "\n",
        "To conduct a repeated measures ANOVA to compare the average daily sales of three retail stores (Store A, Store B, and Store C), we can use the statsmodels library in Python. Repeated measures ANOVA is appropriate when the same subjects (days in this case) are used to test more than one condition (sales from different stores).\n",
        "\n",
        "Here’s how you can simulate the sales data, conduct the repeated measures ANOVA, and follow up with a post-hoc test if necessary:"
      ],
      "metadata": {
        "id": "MlRQk2hvsVIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.anova import AnovaRM\n",
        "import pingouin as pg\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Simulating daily sales data for three stores over 30 days\n",
        "days = 30\n",
        "store_a_sales = np.random.normal(loc=200, scale=20, size=days)  # Store A\n",
        "store_b_sales = np.random.normal(loc=220, scale=20, size=days)  # Store B\n",
        "store_c_sales = np.random.normal(loc=250, scale=20, size=days)  # Store C\n",
        "\n",
        "# Create a DataFrame with sales data\n",
        "data = pd.DataFrame({\n",
        "    'Day': np.arange(1, days+1),\n",
        "    'Store A': store_a_sales,\n",
        "    'Store B': store_b_sales,\n",
        "    'Store C': store_c_sales\n",
        "})\n",
        "\n",
        "# Melt the DataFrame to long format for AnovaRM\n",
        "data_long = data.melt(id_vars='Day', value_vars=['Store A', 'Store B', 'Store C'],\n",
        "                      var_name='Store', value_name='Sales')\n",
        "\n",
        "# Conducting repeated measures ANOVA\n",
        "anova_results = AnovaRM(data_long, 'Sales', 'Day', within=['Store']).fit()\n",
        "\n",
        "# Display ANOVA results\n",
        "print(anova_results)\n",
        "\n",
        "# Check if ANOVA is significant\n",
        "if anova_results.anova_table['Pr > F'].iloc[0] < 0.05:\n",
        "    print(\"Result: Reject the null hypothesis. There are significant differences in sales between the stores.\")\n",
        "\n",
        "    # Post-hoc test (pairwise comparison)\n",
        "    post_hoc = pg.pairwise_ttests(data=data_long, dv='Sales', within='Store', padjust='bonf')\n",
        "    print(\"\\nPost-hoc Test Results:\")\n",
        "    print(post_hoc)\n",
        "else:\n",
        "    print(\"Result: Fail to reject the null hypothesis. No significant differences in sales.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "zI2JCgpSss5M",
        "outputId": "d680529d-8973-426a-d8ac-6fa3235ccba5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pingouin'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e5ac88cc91e7>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manova\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnovaRM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpingouin\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Set random seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pingouin'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}