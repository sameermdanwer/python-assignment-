{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmfh/gh2YQVaoirZpNDF0d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameermdanwer/python-assignment-/blob/main/Regression_Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is Elastic Net Regression and how does it differ from other regression techniques?\n",
        "\n",
        "\n",
        "Elastic Net Regression is a regularized regression technique that combines the benefits of both Lasso Regression (L1 regularization) and Ridge Regression (L2 regularization). It is particularly useful when dealing with datasets that exhibit multicollinearity or when the number of predictors exceeds the number of observations. Here’s a detailed look at Elastic Net Regression and its differences from other regression techniques.\n",
        "\n",
        "# Definition of Elastic Net Regression\n",
        "Elastic Net combines both L1 and L2 regularization techniques into a single loss function. The model's objective function is as follows:\n",
        "\n",
        "[\n",
        "\\text{Loss} = \\text{RSS} + \\lambda_1 \\sum_{j=1}^{p} | \\beta_j | + \\lambda_2 \\sum_{j=1}^{p} \\beta_j^2\n",
        "]\n",
        "\n",
        "where:\n",
        "\n",
        "* RSS is the residual sum of squares.\n",
        "* ( \\beta_j ) represents the coefficient for the ( j )-th predictor.\n",
        "* ( \\lambda_1 ) controls the strength of the L1 penalty (similar to Lasso).\n",
        "* ( \\lambda_2 ) controls the strength of the L2 penalty (similar to Ridge).\n",
        "# Key Characteristics of Elastic Net Regression\n",
        "1. Combination of Regularizations: Elastic Net incorporates both L1 and L2 penalties. This allows it to benefit from variable selection (like Lasso) while also handling multicollinearity (like Ridge).\n",
        "\n",
        "2. Flexibility: The technique allows for a balancing parameter ( \\alpha ) (where ( \\alpha ) is in the range [0, 1]) to define the ratio of L1 and L2 penalties:\n",
        "\n",
        "If ( \\alpha = 1 ), Elastic Net is equivalent to Lasso Regression.\n",
        "If ( \\alpha = 0 ), it is equivalent to Ridge Regression.\n",
        "3. Works Well with High-Dimensional Data: Elastic Net is particularly effective when the number of predictors is larger than the number of observations, and also when a group of features is correlated together.\n",
        "\n",
        "# Differences from Other Regression Techniques\n",
        "1. Lasso Regression:\n",
        "\n",
        "* Penalization: Lasso uses L1 regularization, which tends to shrink some coefficients all the way to zero, effectively performing variable selection.\n",
        "* Multicollinearity: Lasso might arbitrarily select one variable from a group of correlated features, ignoring others.\n",
        "* Elastic Net Advantage: By combining L1 and L2 penalties, Elastic Net can keep multiple correlated predictors in the model while still performing variable selection.\n",
        "2. Ridge Regression:\n",
        "\n",
        "* Penalization: Ridge uses L2 regularization, which shrinks coefficients but does not set any to zero, thus retaining all features in the model.\n",
        "* Variable Selection: Ridge does not perform variable selection; all included variables remain in the final model, making it less interpretable when many variables are correlated.\n",
        "* Elastic Net Advantage: Elastic Net can eliminate unnecessary features while still retaining correlated ones.\n",
        "3. Ordinary Least Squares (OLS):\n",
        "\n",
        "* No Regularization: OLS does not incorporate any form of regularization, making it more susceptible to overfitting, especially in high-dimensional datasets.\n",
        "* Multicollinearity: OLS can fail to produce stable estimates if predictors are highly correlated.\n",
        "* Elastic Net Advantage: Elastic Net mitigates issues associated with multicollinearity and overfitting through its regularization terms.\n",
        "4. Generalized Linear Models (GLM):\n",
        "\n",
        "While GLMs, including logistic regression and Poisson regression, model the relationship between predictors and outcomes using different distributions, Elastic Net applies to linear relationships with penalization, specifically handling multicollinearity and overfitting via regularization.\n",
        "# When to Use Elastic Net\n",
        "* High-Dimensional Data: Elastic Net is useful when dealing with a large number of predictors and when there are strong correlations among them.\n",
        "* Feature Selection: When the goal is to obtain a simpler model with selected features, while still taking advantage of Ridge’s capacity to handle multicollinearity.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XMfG32Wiaen9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?\n",
        "\n",
        "Choosing the optimal values of the regularization parameters for Elastic Net Regression is crucial for obtaining a model that balances fit and complexity. Elastic Net has two regularization parameters: ( \\lambda_1 ) (for the L1 regularization part) and ( \\lambda_2 ) (for the L2 regularization part). Additionally, the mixing parameter ( \\alpha ) specifies the balance between L1 and L2 penalties. Here are the commonly used methods to select these optimal values:\n",
        "\n",
        "# 1. Cross-Validation\n",
        "Cross-validation is the most widely used technique for hyperparameter selection. This involves the following steps:\n",
        "\n",
        "* K-Fold Cross-Validation:\n",
        "\n",
        "* Split the dataset into ( K ) folds.\n",
        "* For a grid of candidate values for ( \\lambda_1 ), ( \\lambda_2 ), and ( \\alpha ), follow these steps:\n",
        "* For each combination of parameters:\n",
        "* Train the model on ( K-1 ) folds.\n",
        "* Calculate a performance metric (e.g., Mean Squared Error (MSE) or R-squared) on the validation set.\n",
        "* Repeat the process for all folds and average the performance metrics for each parameter combination.\n",
        "* Grid Search or Randomized Search:\n",
        "\n",
        "* Grid Search: Systematically search through predefined values of ( \\lambda_1 ), ( \\lambda_2 ), and ( \\alpha ).\n",
        "* Randomized Search: Instead of a fixed grid, randomly sample from a distribution of values for ( \\lambda_1 ), ( \\lambda_2 ), and ( \\alpha ). This can sometimes be more efficient, allowing you to find good parameters with fewer model fits.\n",
        "# 2. Regularization Path\n",
        "Use algorithms (such as Least Angle Regression combined with Lasso, or coordinate descent algorithms) that compute the entire path of solutions as the regularization parameters vary. This can reveal:\n",
        "\n",
        "* How the coefficients change with different values of ( \\lambda_1 ), ( \\lambda_2 ), and ( \\alpha ).\n",
        "* The point at which the model begins to show signs of overfitting or where performance metrics stabilize.\n",
        "# 3. Information Criteria\n",
        "Use information criteria like the AIC (Akaike Information Criterion) or BIC (Bayesian Information Criterion) to assess the trade-off between model fit and complexity. The optimal ( \\lambda_1 ), ( \\lambda_2 ), and ( \\alpha ) values would be those that minimize these criteria.\n",
        "\n",
        "# 4. Coefficient Stability and Visualization\n",
        "* Visualize the model’s coefficients across different values of ( \\lambda_1 ), ( \\lambda_2 ), and ( \\alpha ). Look for:\n",
        "* Stability in coefficients across a range of values, which may indicate a robust model.\n",
        "* The presence of an \"elbow\" in plots of performance metrics versus parameter values, indicating the point where further increases in ( \\lambda ) yield diminishing returns.\n",
        "# 5. Adaptive Methods\n",
        "* Certain modern techniques offer adaptive parameter selection, automatically adjusting ( \\lambda_1 ), ( \\lambda_2 ), and ( \\alpha ) during training based on performance metrics, potentially using approaches like Bayesian optimization.\n",
        "# 6. Empirical Bayes and More Advanced Techniques\n",
        "* Techniques like empirical Bayes can allow for Bayesian approaches to regularization parameter selection, optimizing the overall model fit."
      ],
      "metadata": {
        "id": "-gJ6TqE_a_xW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. What are the advantages and disadvantages of Elastic Net Regression?\n",
        "\n",
        "# Advantages of Elastic Net Regression\n",
        "1. Feature Selection:\n",
        "\n",
        "Elastic Net can perform automatic variable selection by shrinking some coefficients to zero (similar to Lasso), which helps in identifying relevant features in high-dimensional datasets.\n",
        "2. Handling Multicollinearity:\n",
        "\n",
        "Elastic Net is particularly effective in cases where predictor variables are highly correlated. While Lasso might select only one variable from a group of correlated features, Elastic Net can retain multiple variables by combining L1 and L2 penalties. This improves model stability and interpretability.\n",
        "3. Flexibility:\n",
        "\n",
        "The ability to adjust the mixing parameter ( \\alpha ) allows Elastic Net to balance between Lasso and Ridge. This flexibility makes it adaptable to different data structures and allows the user to fine-tune regularization based on specific use cases.\n",
        "4. Robust to Overfitting:\n",
        "\n",
        "By incorporating regularization, Elastic Net helps control overfitting, particularly in high-dimensional spaces where the risk of overfitting is significant.\n",
        "5. Improved Prediction Accuracy:\n",
        "\n",
        "In scenarios where predictors have complex relationships, Elastic Net can provide better predictive performance compared to models that use solely Lasso or Ridge alone.\n",
        "6. Interpretability:\n",
        "\n",
        "The process of variable selection helps in developing more interpretable models, as it reduces the number of features, leading to simpler and more understandable models.\n",
        "# Disadvantages of Elastic Net Regression\n",
        "1. Hyperparameter Tuning:\n",
        "\n",
        "Elastic Net requires the estimation of multiple hyperparameters (( \\lambda_1, \\lambda_2, ) and ( \\alpha )). This tuning can be computationally intensive and may require cross-validation, which can increase model training time and complexity.\n",
        "2. Model Complexity:\n",
        "\n",
        "Despite reducing the number of features, the overall methodology can be perceived as more complex than traditional linear regression, making it harder for practitioners to understand and interpret particularly for users less familiar with regularization techniques.\n",
        "3. Non-Unique Solutions:\n",
        "\n",
        "Similar to other regularization methods, Elastic Net may not always yield a unique solution, especially in cases of high multicollinearity. Different parameter settings can lead to similar performance metrics, complicating model selection.\n",
        "4. Sensitivity to Scaling:\n",
        "\n",
        "The features should be standardized (scaled to zero mean and unit variance) before applying Elastic Net since the regularization parameters are sensitive to the scale of the features. This adds an extra preprocessing step.\n",
        "5. Limited Interpretability with Correlated Features:\n",
        "\n",
        "While Elastic Net retains multiple correlated features, the final model coefficients can be difficult to interpret, especially when multiple features are included that may contribute similarly to the response variable.\n",
        "6. Potential Computational Complexity:\n",
        "\n",
        "Depending on the optimization algorithms used and the size of the dataset, Elastic Net can be computationally intensive compared to simpler linear regression models, particularly with large datasets or high-dimensional spaces."
      ],
      "metadata": {
        "id": "rQpDxaVkelCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. What are some common use cases for Elastic Net Regression?\n",
        "\n",
        "\n",
        "Elastic Net Regression is widely used in various fields due to its ability to handle high-dimensional datasets, multicollinearity, and its built-in feature selection capabilities. Here are some common use cases:\n",
        "\n",
        "# 1. Genomics and Bioinformatics\n",
        "* Gene Expression Data: In genomics, datasets often have a large number of gene expressions (features) relative to the number of samples. Elastic Net can be used to identify significant genes that predict outcomes (e.g., disease status) while managing multicollinearity among correlated genes.\n",
        "* Lasso and Ridge Comparison: Elastic Net is particularly useful in scenarios where gene sets are often correlated, allowing researchers to retain information from multiple correlated genes instead of arbitrarily selecting one.\n",
        "# 2. Medical Research\n",
        "* Clinical Predictive Modeling: In healthcare analytics, Elastic Net can help build models predicting patient outcomes based on various clinical features (e.g., lab results, medical history) where the number of features may far exceed the number of patient observations.\n",
        "* Risk Assessment: Identifying risk factors associated with diseases or treatment efficacy, where multiple factors are correlated.\n",
        "# 3. Finance and Economics\n",
        "* Credit Scoring: Elastic Net can be employed to build credit scoring models that evaluate the creditworthiness of individuals based on numerous financial indicators, many of which might be correlated.\n",
        "* Portfolio Optimization: In finance, Elastic Net can assist in selecting a subset of assets that minimize risk while maximizing returns based on historical data.\n",
        "# 4. Marketing and Customer Analytics\n",
        "* Customer Segmentation: Businesses can use Elastic Net to analyze customer data, identifying key features that contribute to customer behavior (such as purchase habits) and tailor marketing strategies accordingly.\n",
        "* Predictive Modeling for Churn: Predicting customer churn based on various features can leverage Elastic Net to balance the trade-off between including many features and maintaining model interpretability.\n",
        "# 5. Environmental Science\n",
        "* Predicting Environmental Outcomes: In studies predicting environmental outcomes (like pollution levels), Elastic Net can help assess the impact of various environmental regulations and conditions, especially when dealing with correlated environmental predictors.\n",
        "* Remote Sensing: Analyzing satellite imagery data often leads to high-dimensional datasets, where Elastic Net can effectively select important features for predicting specific environmental phenomena.\n",
        "# 6. Social Sciences and Psychology\n",
        "* Survey Analysis: In studies using surveys with many questions (features) and relatively few respondents, Elastic Net can help identify essential predictors of psychological constructs or behaviors while managing multicollinearity.\n",
        "* Predictive Modeling: Understanding social phenomena where overlapping factors influence behaviors and outcomes.\n",
        "# 7. Natural Language Processing (NLP)\n",
        "* Text Classification: When dealing with high-dimensional text data (e.g., term frequency-inverse document frequency features), Elastic Net can help in feature selection for text classification tasks while managing multicollinearity among correlated terms.\n",
        "* Sentiment Analysis: Modeling sentiment based on multiple features derived from texts, where features may be correlated.\n",
        "# 8. Engineering and Manufacturing\n",
        "* Quality Control: In manufacturing, analyzing various parameters affecting product quality can benefit from Elastic Net, especially when many parameters may be interrelated.\n",
        "* Predictive Maintenance: Modeling and predicting machine failures based on sensor data can be approached using Elastic Net to identify significant predictors from potentially correlated sensor readings."
      ],
      "metadata": {
        "id": "Nf7k0S_afPz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. How do you interpret the coefficients in Elastic Net Regression?\n",
        "\n",
        "\n",
        "Interpreting the coefficients in Elastic Net Regression is similar to interpreting coefficients in traditional linear regression, but special consideration must be given due to the regularization involved. Here are the key points to understand when interpreting the coefficients:\n",
        "\n",
        "# 1. Coefficient Magnitude and Sign\n",
        "* Magnitude: The size of the coefficient indicates the strength of the relationship between the corresponding feature and the outcome variable. A larger absolute value implies a stronger impact on the predicted outcome.\n",
        "* Sign: The sign (positive or negative) of a coefficient indicates the direction of the relationship:\n",
        "* A positive coefficient means that as the predictor variable increases, the response variable also tends to increase, assuming all other variables remain constant.\n",
        "* A negative coefficient implies that as the predictor variable increases, the response variable tends to decrease.\n",
        "# 2. Standardized Coefficients\n",
        "* When using Elastic Net, it is common practice to standardize the predictor variables (scale to zero mean and unit variance) before fitting the model. Thus, the coefficients represent the change in the response variable for a one standard deviation change in the predictor variable.\n",
        "* This standardization allows you to compare the relative importance of different predictors on the outcome, providing insights into which features are more influential.\n",
        "# 3. Interpretation of Zero Coefficients\n",
        "* Elastic Net can shrink some coefficients to zero, effectively selecting for you the most relevant variables. A coefficient of zero means that the associated predictor variable does not contribute to the prediction of the response variable given the other predictors in the model.\n",
        "* This feature selection aspect is particularly valuable in high-dimensional datasets, as it can help simplify the model and improve interpretability.\n",
        "# 4. Interactions with Regularization\n",
        "* Due to the combination of L1 (Lasso) and L2 (Ridge) penalties, the coefficients in Elastic Net can behave differently than those in ordinary least squares regression. The L1 component can cause sparsity (some coefficients being exactly zero), while the L2 component helps to stabilize the estimates of the coefficients of correlated features.\n",
        "* This dual influence means that interpretation should also consider the potential correlation between predictors. A feature that is highly correlated with another might not have the coefficient size that matches intuitively with its perceived importance due to the elastic net’s regularization effects.\n",
        "# 5. Interdependency of Coefficients\n",
        "* Since Elastic Net can retain multiple correlated predictors, the effects of each predictor don’t operate independently. If predictors ( X1 ) and ( X2 ) are correlated and included in the model, the interpretation of ( X1 )'s coefficient assumes that ( X2 ) is held constant, and vice versa.\n",
        "* This might mean that while both ( X1 ) and ( X2 ) contribute to the prediction, interpreting them in isolation can be misleading unless their interrelationship is well understood.\n",
        "# 6. Contextual Interpretation\n",
        "* The context of the data and the specific application is vital for interpreting coefficients. The coefficients should be examined within the framework of the subject matter to make informed conclusions about their meaning and implications—e.g., interpreting the effect of a unit increase in expenditures on sales in a marketing context, or understanding the effect of a one-unit change in a health indicator on disease risk."
      ],
      "metadata": {
        "id": "lqWBIDIMgQ2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6. How do you handle missing values when using Elastic Net Regression?\n",
        "\n",
        "Handling missing values is a crucial step when preparing data for Elastic Net Regression (or any regression analysis) since most regression algorithms, including Elastic Net, do not natively support datasets with missing values. Here are several strategies you can use to effectively manage missing values in your dataset:\n",
        "\n",
        "# 1. Remove Missing Values\n",
        "* Complete Case Analysis (Listwise Deletion): This is the simplest approach, where you remove any observations (rows) with missing values. While easy to implement, this can lead to a significant loss of data, particularly if missingness is prevalent.\n",
        "* Pairwise Deletion: Instead of removing entire rows, this method only excludes the missing values in calculations. However, it can introduce inconsistencies and complications in interpreting results.\n",
        "# 2. Imputation Techniques\n",
        "   Imputation replaces missing values with substituted values. Popular methods include:\n",
        "\n",
        "* Mean/Median/Mode Imputation: Replace missing values with the mean (or median, for skewed distributions) for continuous features or the mode for categorical features. This is simple but can underestimate the variability and can lead to biased estimates if the data isn't missing completely at random (MCAR).\n",
        "\n",
        "* K-Nearest Neighbors (KNN) Imputation: This involves using the nearest neighbors to impute missing values based on the values of other similar observations in the dataset. KNN can provide a better estimate than mean or median imputation but is more computationally intensive.\n",
        "\n",
        "* Multiple Imputation: This technique creates multiple datasets with imputed values, performing the analysis on each and then combining the results. This helps account for the uncertainty around the missing values but is more complex to implement.\n",
        "\n",
        "# 3. Predictive Modeling for Imputation\n",
        "* Use sophisticated models (e.g., Elastic Net itself, Random Forests) to predict and fill missing values based on known features. This method leverages relationships in the data that can lead to more accurate imputations.\n",
        "# 4. Flagging Missing Values\n",
        "* Create binary indicators for features with missing values (e.g., 1 for missing, 0 for present) and include them in the model as additional predictors. This approach allows you to retain potentially useful information about missingness while including the feature itself with imputed values.\n",
        "# 5. Use Algorithms That Handle Missing Values\n",
        "* Some methods are inherently capable of handling missing values (e.g., tree-based methods such as Random Forests). You can also preprocess the data in such a way to apply these techniques first to impute or analyze missing values before applying Elastic Net."
      ],
      "metadata": {
        "id": "Lnuv_MVHhGKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'feature1': [1, 2, None, 4],\n",
        "    'feature2': [None, 2, 3, 4],\n",
        "    'target': [1, 0, 1, 0]\n",
        "})\n",
        "\n",
        "# Imputation\n",
        "imp = SimpleImputer(strategy='mean')\n",
        "data[['feature1', 'feature2']] = imp.fit_transform(data[['feature1', 'feature2']])\n",
        "\n",
        "# Splitting the dataset\n",
        "X = data[['feature1', 'feature2']]\n",
        "y = data['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit Elastic Net Model\n",
        "model = ElasticNet()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "e3Q-Funsh5a5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7. How do you use Elastic Net Regression for feature selection?\n",
        "\n",
        "Elastic Net Regression is a regularization technique that combines the properties of both Lasso (L1) and Ridge (L2) regression. It is particularly useful in situations where you have a large number of features, and there may be correlations among them. Here’s how you can use Elastic Net Regression for feature selection:\n",
        "\n",
        "# Steps to Use Elastic Net Regression for Feature Selection\n",
        "1. Data Preparation:\n",
        "\n",
        "Gather and preprocess your dataset, which includes handling missing values, encoding categorical variables, and scaling the features (standardization is generally a good practice with Elastic Net).\n",
        "2. Splitting the Data:\n",
        "\n",
        "Divide your dataset into training and testing sets to evaluate the model's performance later.\n",
        "3. Define the Elastic Net Model:\n",
        "\n",
        "Use a library like scikit-learn in Python, TensorFlow, or others to define your Elastic Net model. In Python, it can be done like this:"
      ],
      "metadata": {
        "id": "TgvrDtCwhu2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet"
      ],
      "metadata": {
        "id": "YW8LcbKgieTs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.  Hyperparameter Tuning:\n",
        "\n",
        "Elastic Net has two main hyperparameters: alpha (the overall strength of the regularization) and l1_ratio (the proportion of L1 regularization). You can perform grid search or randomized search to find the best combination of these hyperparameters. Here's an example of using GridSearchCV with Elastic Net:"
      ],
      "metadata": {
        "id": "KMjIZon-iggZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [0.01, 0.1, 1.0, 10.0],\n",
        "    'l1_ratio': [0.1, 0.5, 0.9]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(ElasticNet(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "l5T16P5qivKX",
        "outputId": "666c5601-0248-4e63-98b3-8045719adf9e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4e3c6621a42c>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    975\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0mfit_and_score_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m                     )\n\u001b[0;32m--> 977\u001b[0;31m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0m\u001b[1;32m    978\u001b[0m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrouted_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    410\u001b[0m                 (\n\u001b[1;32m    411\u001b[0m                     \u001b[0;34m\"Cannot have number of splits n_splits={0} greater\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot have number of splits n_splits=5 greater than the number of samples: n_samples=3."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Fit the Model:\n",
        "\n",
        "Use the best parameters found to fit your model on the training data."
      ],
      "metadata": {
        "id": "P2Z_r7Nxi2vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "best_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "35S1dV69i5ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Examine Coefficients:\n",
        "\n",
        "After fitting, examine the coefficients of the features in the trained model. Features with non-zero coefficients are selected, while features that have been driven to zero by L1 regularization can be considered unimportant for the model."
      ],
      "metadata": {
        "id": "B2AMZyh7i8va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importance = best_model.coef_\n",
        "features = X.columns\n",
        "feature_importance = pd.DataFrame({'Feature': features, 'Importance': importance})"
      ],
      "metadata": {
        "id": "tw9H6SQGjX1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Feature Selection:\n",
        "\n",
        "Set a threshold for the coefficients to determine which features to retain. For example, you may choose to keep all features where the coefficient is greater than a small epsilon (e.g., > 0)."
      ],
      "metadata": {
        "id": "Gzreg5bxjY_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = feature_importance[feature_importance['Importance'] != 0]"
      ],
      "metadata": {
        "id": "yZ45Z2Yvjdsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Model Evaluation:\n",
        "\n",
        "Evaluate your model’s performance using metrics such as Mean Squared Error (MSE), R-squared, or cross-validation scores on the test dataset to ensure that the regularization has improved the model without losing significant predictive power.\n",
        "9. Final Model:\n",
        "\n",
        "After selection, you can retrain your model on the selected features only, which may improve interpretability and reduce overfitting."
      ],
      "metadata": {
        "id": "_iPPJKHTje5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?\n",
        "\n",
        "In Python, you can use the pickle module to serialize (pickle) and deserialize (unpickle) objects, such as a trained Elastic Net Regression model. Here’s how to do it step-by-step:\n",
        "\n",
        "# Step 1: Train Your Elastic Net Regression Model\n",
        "First, you need to train your Elastic Net model. For demonstration purposes, here's a simple example:"
      ],
      "metadata": {
        "id": "siNaoxHCjo3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample data\n",
        "X = np.random.rand(100, 10)  # 100 samples, 10 features\n",
        "y = np.random.rand(100)       # 100 target values\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Elastic Net model\n",
        "model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "hiQe9FGLj11I",
        "outputId": "04b8098c-8144-4e8d-cac3-7664e5b4e92a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Pickle the Trained Model\n",
        "After training the model, use pickle to save it to a file."
      ],
      "metadata": {
        "id": "f73-TFINj6lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Specify the filename\n",
        "filename = 'elastic_net_model.pkl'\n",
        "\n",
        "# Save the model using pickle\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "print(\"Model saved to\", filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo1srMQwj8Pg",
        "outputId": "8dc976a8-8d47-4c71-c624-7003fd24804a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to elastic_net_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Unpickle the Model"
      ],
      "metadata": {
        "id": "fHeqTKoIj-tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the file\n",
        "with open(filename, 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "print(\"Model loaded from\", filename)\n",
        "\n",
        "# You can now use the loaded_model to make predictions\n",
        "predictions = loaded_model.predict(X_test)\n",
        "print(\"Predictions:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmtRR5_nkDb3",
        "outputId": "0e997f01-521c-4b93-df41-28bd60f80f5d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from elastic_net_model.pkl\n",
            "Predictions: [0.54494101 0.54494101 0.54494101 0.54494101 0.54494101 0.54494101\n",
            " 0.54494101 0.54494101 0.54494101 0.54494101 0.54494101 0.54494101\n",
            " 0.54494101 0.54494101 0.54494101 0.54494101 0.54494101 0.54494101\n",
            " 0.54494101 0.54494101]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9. What is the purpose of pickling a model in machine learning?\n",
        "\n",
        "Pickling a model in machine learning serves several important purposes:\n",
        "\n",
        "# 1. Persistence:\n",
        "* Save the State: Once a machine learning model is trained, you may want to save its state, including learned parameters (weights and biases) and configurations. Pickling allows you to capture this complete state.\n",
        "* Avoid Retraining: By pickling a model, you avoid the need to retrain it every time you want to use it, saving both time and computational resources.\n",
        "# 2. Model Deployment:\n",
        "* Easier Deployment: Pickled models can be easily loaded into a production environment, making it straightforward to deploy machine learning applications without repeatedly training models.\n",
        "* Integration: Pickled models can be easily integrated into applications, web services, or APIs to provide predictions in real-time or batch processing scenarios.\n",
        "# 3. Version Control:\n",
        "* Model Versions: By pickling models after different training runs, you can keep track of various versions of your model. This is useful for maintaining different iterations and comparing their performances.\n",
        "# 4. Sharing:\n",
        "* Collaboration: Models can be easily shared with colleagues or other teams. Sharing a pickled model facilitates collaboration, as others can load and use the model without needing access to the original training data or code.\n",
        "* Reproducibility: Ensuring that others can replicate your results becomes easier when you provide a pickled model along with your code, making it possible to load and evaluate exactly what was produced.\n",
        "# 5. Integration with Other Systems:\n",
        "Cross-Tool Compatibility: Pickled models can be used across different frameworks and libraries that support Python's pickle module, enabling better integration with other systems and workflows.\n",
        "# 6. Time Management:\n",
        "* Quick Prototyping: For rapid development cycles, pickled models allow for faster prototyping. You can iterate on model improvements without the overhead of retraining from scratch.\n",
        "# 7. Data Versioning:\n",
        "* Fragmentation of Data: When working with large datasets, it might be impractical to keep the entire dataset available. A pickled model allows results to be stored separately from the data, focusing on the model's trained state."
      ],
      "metadata": {
        "id": "28Ivz3GikGnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KzrS5LEUkrZ6"
      }
    }
  ]
}