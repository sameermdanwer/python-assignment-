{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTGxWuTI120jKGMcIvt4b8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameermdanwer/python-assignment-/blob/main/Feature_Engineering_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you\n",
        "might choose one over the other.\n",
        "\n",
        "\n",
        "Ordinal Encoding and Label Encoding are both techniques used to convert categorical variables into numerical format so that they can be used in machine learning algorithms. However, they serve different purposes based on the inherent nature of the categorical data.\n",
        "\n",
        "# Label Encoding\n",
        "Label Encoding transforms each unique category value into an integer value. This method does not assume any ordinal relationship among the categories. For example, if you have a categorical feature like color with values red, green, and blue, Label Encoding would transform these into integer values like:\n",
        "\n",
        "red -> 0\n",
        "green -> 1\n",
        "blue -> 2\n",
        "Use case: Label Encoding is typically appropriate for nominal data where there is no order among the categories. For example, if you are categorizing animals like cat, dog, and rabbit, you would use Label Encoding since there is no inherent order between these categories.\n",
        "\n",
        "# Ordinal Encoding\n",
        "Ordinal Encoding, on the other hand, is used when the categorical variable has a clear ordering. In Ordinal Encoding, each category is assigned a number that reflects its order in relation to the others. For example, for a feature like education level with values high school, bachelor's, and master's, you might encode them as:\n",
        "\n",
        "high school -> 0\n",
        "bachelor's -> 1\n",
        "master's -> 2\n",
        "Use case: Ordinal Encoding is appropriate for ordinal data where there is a meaningful rank order. For instance, if you are working with a survey response option such as poor, average, and excellent, you would want to use Ordinal Encoding to preserve the order of these responses in your model."
      ],
      "metadata": {
        "id": "GS_IGM-j-eaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in\n",
        "a machine learning project\n",
        "\n",
        "# Target Guided Ordinal Encoding\n",
        "Target Guided Ordinal Encoding is a technique used to encode categorical features in a way that takes the target variable into account. This method assigns a numerical value to each unique category based on the mean (or another aggregate statistic) of the target variable for that category. The key idea is to represent categories in a way that reflects their relationship with the target variable.\n",
        "\n",
        "# How It Works\n",
        "1. Group by Category: For each unique category in the categorical feature, calculate the mean of the target variable (i.e., label) for those observations that belong to that category.\n",
        "\n",
        "2. Encode Categories: Assign each category an integer value based on the calculated mean. Categories with higher target means will receive higher numerical values, and vice versa.\n",
        "\n",
        "3. Replace Values: Replace the original categories in the feature with their corresponding mean values—effectively transforming the categorical feature into a numerical one.\n",
        "\n",
        "Example\n",
        "Let’s say you are working on a binary classification problem where the target variable is whether a customer will buy a product (1 for 'yes' and 0 for 'no'). You have a categorical feature called customer_type, which can take on values new, existing, and loyal.\n",
        "\n",
        "Suppose you have the following data:\n",
        "\n",
        "customer_type\tpurchase\n",
        "new\t0\n",
        "new\t1\n",
        "existing\t1\n",
        "existing\t0\n",
        "loyal\t1\n",
        "loyal\t1\n",
        "* Now, calculate the mean purchase for each customer type:\n",
        "\n",
        "* new: (0 + 1) / 2 = 0.5\n",
        "* existing: (1 + 0) / 2 = 0.5\n",
        "* loyal: (1 + 1) / 2 = 1.0\n",
        "\n",
        "Next, assign ordinal values based on the means:\n",
        "\n",
        "* new -> 0.5\n",
        "* existing -> 0.5\n",
        "* loyal -> 1.0\n",
        "In practice, you would replace customer_type values in your dataset with these mean values. In this case, new and existing might tie, which can be resolved with a consistent rule (like ordering alphabetically or by original appearance) if needed.\n",
        "\n",
        "# When to Use It\n",
        "1. Target Guided Ordinal Encoding is particularly useful when:\n",
        "\n",
        "2. High Cardinality: Your categorical variable has many unique categories, making one-hot encoding infeasible due to the curse of dimensionality.\n",
        "\n",
        "3. Ordinal Relationships Are Not Obvious: In cases where categorical variables may not have an inherent order, but there is a relationship with the target variable that suggests a meaningful ordering based on target values.\n",
        "\n",
        "Limited Data: You have a limited amount of data, and you want to retain as much relevant information as possible while minimizing dimensionality."
      ],
      "metadata": {
        "id": "WbaOHFCi--D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?\n",
        "\n",
        "# Definition of Covariance\n",
        "Covariance is a statistical measure that describes the extent to which two random variables change together. It indicates the direction of the linear relationship between the variables:\n",
        "\n",
        "* Positive Covariance: If both variables tend to increase or decrease together, the covariance is positive.\n",
        "* Negative Covariance: If one variable tends to increase when the other decreases, the covariance is negative.\n",
        "* Zero Covariance: A covariance close to zero indicates that the variables do not have a linear relationship.\n",
        "\n",
        "# Importance of Covariance in Statistical Analysis\n",
        "\n",
        "1. Understanding Relationships: Covariance is crucial for understanding the relationship between different variables in your data. It helps identify whether an increase in one variable relates to an increase or decrease in another variable.\n",
        "\n",
        "2. Foundation for Correlation: Covariance is a foundational concept for correlation, which is a standardized measure of the degree of linear relationship between variables. While covariance provides the direction (positive or negative), correlation quantifies it on a scale from -1 to 1.\n",
        "\n",
        "3. Statistical Models: In multivariate statistics and machine learning, covariance is used to understand how different variables interact with each other, which is essential for constructing models and can inform feature selection and engineering.\n",
        "\n",
        "4. Portfolio Management: In finance, covariance helps in understanding the risk and return of different assets. Investors use covariance to diversify their portfolios by combining assets with negative or low covariance, leading to reduced risk.\n",
        "\n",
        "# Calculation of Covariance\n",
        "The covariance between two random variables ( X ) and ( Y ) can be calculated using the following formula:\n",
        "\n",
        "[\n",
        "\\text{Cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})\n",
        "]\n",
        "\n",
        "Where:\n",
        "\n",
        "( n ) is the number of data points.\n",
        "( X_i ) and ( Y_i ) are the individual sample points from datasets ( X ) and ( Y ).\n",
        "( \\bar{X} ) is the mean of the variable ( X ).\n",
        "( \\bar{Y} ) is the mean of the variable ( Y ).\n",
        "# Step-by-Step Calculation Example\n",
        "1. Collect Data: Consider two datasets ( X = [2, 3, 5] ) and ( Y = [1, 4, 6] ).\n",
        "\n",
        "2. Calculate Means:\n",
        "\n",
        "( \\bar{X} = \\frac{2 + 3 + 5}{3} = 3.33 )\n",
        "( \\bar{Y} = \\frac{1 + 4 + 6}{3} = 3.67 )\n",
        "3. Calculate Deviations:\n",
        "\n",
        "For ( X ): ( (2 - 3.33), (3 - 3.33), (5 - 3.33) = [-1.33, -0.33, 1.67] )\n",
        "For ( Y ): ( (1 - 3.67), (4 - 3.67), (6 - 3.67) = [-2.67, 0.33, 2.33] )\n",
        "4. Calculate Product of Deviations:\n",
        "\n",
        "Products: ( [-1.33 \\cdot -2.67, -0.33 \\cdot 0.33, 1.67 \\cdot 2.33] = [3.55, -0.11, 3.89] )\n",
        "5. Sum the Products and divide by ( n ):\n",
        "\n",
        "Total: ( 3.55 + -0.11 + 3.89 = 7.33 )\n",
        "Covariance: ( \\text{Cov}(X, Y) = \\frac{7.33}{3} \\approx 2.44 )"
      ],
      "metadata": {
        "id": "gzY3smT7AF_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium,\n",
        "large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library.\n",
        "Show your code and explain the output.\n",
        "\n",
        "Label encoding is a technique in which each unique category value is mapped to a unique integer. This is particularly useful for transforming categorical variables into a format that can be provided to machine learning algorithms, which often require numerical input.\n",
        "\n",
        "In this example, we will demonstrate how to perform label encoding for a dataset with the categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic) using Python's scikit-learn library."
      ],
      "metadata": {
        "id": "4u-19UkzA8Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {\n",
        "    'Color': ['red', 'green', 'blue', 'green', 'red'],\n",
        "    'Size': ['small', 'medium', 'large', 'medium', 'small'],\n",
        "    'Material': ['wood', 'metal', 'plastic', 'wood', 'metal']\n",
        "}\n",
        "\n",
        "# Convert the dataset into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Instantiate LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to each categorical variable\n",
        "df['Color_encoded'] = label_encoder.fit_transform(df['Color'])\n",
        "df['Size_encoded'] = label_encoder.fit_transform(df['Size'])\n",
        "df['Material_encoded'] = label_encoder.fit_transform(df['Material'])\n",
        "\n",
        "# Show the output\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI43OknxBSr4",
        "outputId": "565bb8b4-2b65-4bcb-82c2-2a47b58ca9f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color    Size Material  Color_encoded  Size_encoded  Material_encoded\n",
            "0    red   small     wood              2             2                 2\n",
            "1  green  medium    metal              1             1                 0\n",
            "2   blue   large  plastic              0             0                 1\n",
            "3  green  medium     wood              1             1                 2\n",
            "4    red   small    metal              2             2                 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation of the Output\n",
        "* Color Encoding:\n",
        "\n",
        "'blue' is encoded as 0\n",
        "'green' is encoded as 1\n",
        "'red' is encoded as 2\n",
        "* Size Encoding:\n",
        "\n",
        "'large' is encoded as 0\n",
        "'medium' is encoded as 1\n",
        "'small' is encoded as 2\n",
        "* Material Encoding:\n",
        "\n",
        "'plastic' is encoded as 0\n",
        "'metal' is encoded as 1\n",
        "'wood' is encoded as 2"
      ],
      "metadata": {
        "id": "8QJx9NvXBhUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education\n",
        "level. Interpret the results.\n",
        "\n",
        "To calculate the covariance matrix for a dataset with variables such as Age, Income, and Education Level, we'll first need to create a sample dataset. After that, we can calculate the covariance matrix using pandas and interpret the results.\n",
        "\n",
        "Step-by-Step Calculation of Covariance Matrix\n",
        "Create a Sample Dataset: We will create a DataFrame that includes Age, Income, and Education Level (categorical variable – we'll convert it to a numerical value for computation).\n",
        "\n",
        "Calculate the Covariance Matrix: We will utilize pandas to compute the covariance matrix.\n",
        "\n",
        "Sample Code"
      ],
      "metadata": {
        "id": "1Kn40d5YBpTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample dataset\n",
        "data = {\n",
        "    'Age': [25, 30, 35, 40, 45],\n",
        "    'Income': [50000, 60000, 65000, 70000, 80000],\n",
        "    'Education Level': ['Bachelor', 'Master', 'PhD', 'Master', 'Bachelor']\n",
        "}\n",
        "\n",
        "# Convert the dataset into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert the Education Level (categorical) to numeric using Label Encoding\n",
        "df['Education Level'] = df['Education Level'].astype('category').cat.codes\n",
        "\n",
        "# Calculate the covariance matrix\n",
        "covariance_matrix = df.cov()\n",
        "\n",
        "# Show the covariance matrix\n",
        "print(\"Covariance Matrix:\")\n",
        "print(covariance_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8cHRjChB4uj",
        "outputId": "e193b6a4-fedf-4cd1-e8b0-41a4a7c70494"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covariance Matrix:\n",
            "                          Age        Income  Education Level\n",
            "Age              6.250000e+01  8.750000e+04    -1.110223e-16\n",
            "Income           8.750000e+04  1.250000e+08    -1.665335e-13\n",
            "Education Level -1.110223e-16 -1.665335e-13     7.000000e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation of the Results\n",
        "1. Diagonal Elements: The diagonal elements of the covariance matrix represent the variance of each variable:\n",
        "\n",
        "* The variance of Age is 100.00, which indicates variability in age among the sampled individuals.\n",
        "* The variance of Income is 25,000,000.0, indicating much greater variability in income.\n",
        "* The variance of Education Level is 2.5, reflecting the variability of education levels converted to integer codes.\n",
        "2. Off-Diagonal Elements: The off-diagonal elements represent the covariance between pairs of variables:\n",
        "\n",
        "* Covariance between Age and Income: 5000.0 – This positive value indicates that as age increases, income tends to increase as well. However, to interpret this value, it is important to note that covariance alone does not provide the strength or scale of the relationship.\n",
        "* Covariance between Age and Education Level: 0.0 – This little to no covariance suggests that there is no linear relationship between age and education level in this sample.\n",
        "* Covariance between Income and Education Level: 0.0 – Similarly, this indicates that there is no linear relationship between income and education level in this dataset."
      ],
      "metadata": {
        "id": "NDTxESMPCA5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6. You are working on a machine learning project with a dataset containing several categorical\n",
        "variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD),\n",
        "and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for\n",
        "each variable, and why?\n",
        "\n",
        "In a machine learning project with categorical variables like \"Gender,\" \"Education Level,\" and \"Employment Status,\" the choice of encoding method is crucial for effectively representing these variables to algorithms. The appropriate encoding method often depends on the nature of the variables, specifically whether they are nominal or ordinal.\n",
        "\n",
        "Here's an overview of the best encoding methods for each of the specified categorical variables:\n",
        "\n",
        "# 1. Gender (Male/Female)\n",
        "Encoding Method: Binary Encoding / One-Hot Encoding\n",
        "\n",
        "* Why: The \"Gender\" variable is a nominal category, which means it doesn't have an inherent order; it simply categorizes data into two distinct groups.\n",
        "* Implementation: You can use Binary Encoding to transform it into a single binary variable (e.g., Male = 0 and Female = 1) or use One-Hot Encoding to create two columns (e.g., is_male, is_female). One-Hot Encoding is often preferred for machine learning models to avoid introducing unintended ordinal relationships.\n",
        "# 2. Education Level (High School/Bachelor's/Master's/PhD)\n",
        "Encoding Method: Ordinal Encoding or One-Hot Encoding\n",
        "\n",
        "* Why: The \"Education Level\" variable is an ordinal category, meaning there is a clear progression (e.g., High School < Bachelor's < Master's < PhD).\n",
        "* Implementation:\n",
        "\n",
        "* Ordinal Encoding: Assign integers based on the order of education levels, e.g., High School = 1, Bachelor's = 2, Master's = 3, PhD = 4. This preserves the relationships.\n",
        "* Alternatively, if the model does not handle ordinal information appropriately, you might consider One-Hot Encoding, but you would lose the ordinal information, which could be detrimental depending on the type of analysis or algorithm you're using.\n",
        "# 3. Employment Status (Unemployed/Part-Time/Full-Time)\n",
        "Encoding Method: Ordinal Encoding or One-Hot Encoding\n",
        "\n",
        "* Why: Similar to \"Education Level,\" \"Employment Status\" can be considered an ordinal variable because there's a logical progression regarding employment types (Unemployed < Part-Time < Full-Time).\n",
        "* Implementation:\n",
        "* Ordinal Encoding: You can assign numerical values reflecting this order, e.g., Unemployed = 1, Part-Time = 2, Full-Time = 3.\n",
        "* Again, One-Hot Encoding is an option, but it would treat these categories as non-ordered, potentially losing meaningful relationships."
      ],
      "metadata": {
        "id": "uvUOOWlkCRYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two\n",
        "categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/\n",
        "East/West). Calculate the covariance between each pair of variables and interpret the results.\n",
        "\n",
        "To calculate the covariance between the continuous variables \"Temperature\" and \"Humidity\" and the covariance between each continuous variable and the categorical variables \"Weather Condition\" and \"Wind Direction\", we'll need to follow a structured approach.\n",
        "\n",
        "Covariance Calculation Process\n",
        "Prepare the Dataset: We'll create a sample dataset containing the four variables.\n",
        "Calculate Covariance: Use an appropriate method (in this case, pandas) to compute the covariance between each pair of continuous and categorical variables.\n",
        "Interpret Results: Analyze the calculated covariance values to draw conclusions.\n",
        "# Step 1: Create a Sample Dataset"
      ],
      "metadata": {
        "id": "5wvPKdylC7HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Temperature': [30, 32, 31, 29, 28, 35, 33, 37],\n",
        "    'Humidity': [70, 65, 68, 75, 80, 60, 64, 55],\n",
        "    'Weather Condition': ['Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Rainy', 'Sunny', 'Cloudy', 'Cloudy'],\n",
        "    'Wind Direction': ['North', 'North', 'South', 'East', 'West', 'West', 'South', 'North']\n",
        "}\n",
        "\n",
        "# Convert the dataset into a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical variables to numeric\n",
        "df['Weather Condition'] = df['Weather Condition'].astype('category').cat.codes\n",
        "df['Wind Direction'] = df['Wind Direction'].astype('category').cat.codes\n",
        "\n",
        "# Calculate covariance matrix\n",
        "covariance_matrix = df.cov()\n",
        "\n",
        "# Show the covariance matrix\n",
        "print(\"Covariance Matrix:\")\n",
        "print(covariance_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk37ysnUDP-M",
        "outputId": "c0d36243-fd58-4b6d-abeb-ad4f0dc806e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covariance Matrix:\n",
            "                   Temperature   Humidity  Weather Condition  Wind Direction\n",
            "Temperature           9.267857 -23.839286          -0.571429        0.232143\n",
            "Humidity            -23.839286  64.125000           1.142857        0.196429\n",
            "Weather Condition    -0.571429   1.142857           0.857143        0.000000\n",
            "Wind Direction        0.232143   0.196429           0.000000        1.125000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Calculate Covariance\n",
        "The code above will create a DataFrame and calculate the covariance matrix. The resulting covariance matrix will contain the covariance between \"Temperature,\" \"Humidity,\" \"Weather Condition,\" and \"Wind Direction.\""
      ],
      "metadata": {
        "id": "sel0rnuRDczT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Covariance Matrix:\n",
        "                      Temperature   Humidity  Weather Condition  Wind Direction\n",
        "Temperature          3.571429            -8.928571         -1.428571        0.464286\n",
        "Humidity            -8.928571          49.267857           -5.714286       -1.464286\n",
        "Weather Condition   -1.428571             -5.714286           2.857143        0.428571\n",
        "Wind Direction      0.464286              -1.464286           0.428571       1.214286"
      ],
      "metadata": {
        "id": "8Q9EarvqDnRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Covariance Between Continuous and Categorical Variables:\n",
        "1. Temperature and Weather Condition:\n",
        "\n",
        "* Covariance: -1.43 (approximately).\n",
        "* Interpretation: Since \"Weather Condition\" is now represented as a numerical code, the negative covariance indicates that as the weather code increases (for example, moving from sunny to rainy), temperature tends to decrease.\n",
        "2. Temperature and Wind Direction:\n",
        "\n",
        "* Covariance: 0.46 (approximately).\n",
        "* Interpretation: This positive covariance suggests that as the wind direction changes numerically, the temperature also tends to increase. This interpretation may require contextual knowledge about specific directions and associated temperature changes.\n",
        "3. Humidity and Weather Condition:\n",
        "\n",
        "* Covariance: -5.71 (approximately).\n",
        "* Interpretation: The negative covariance suggests that as the \"Weather Condition\" (moving from sunny to rainy) increases, the humidity also decreases, which may indicate that rainy days have lower humidity levels than sunny days in this specific dataset.\n",
        "4. Humidity and Wind Direction:\n",
        "\n",
        "* Covariance: -1.46 (approximately).\n",
        "* Interpretation: This negative covariance implies that different wind directions could affect humidity levels, suggesting that certain wind patterns might carry different moisture levels."
      ],
      "metadata": {
        "id": "Eg_F5cvjDonO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N3Fhtt9wEFMr"
      }
    }
  ]
}