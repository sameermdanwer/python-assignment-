{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwOglJLsIblEUqFt3ug8vg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameermdanwer/python-assignment-/blob/main/Multiprocessing_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is multiprocessing in python? Why is it useful?\n",
        "\n",
        "# Multiprocessing\n",
        "in Python refers to the ability to run multiple processes concurrently. Python's multiprocessing module provides a way to create processes, enabling parallel execution of code. Each process runs independently, and they can execute different tasks simultaneously, taking full advantage of multiple CPU cores.\n",
        "\n",
        "#  Key features of the multiprocessing module:\n",
        "\n",
        "* Process: Represents an individual process.\n",
        "* Queue & Pipe: Mechanisms to allow processes to communicate with each other.\n",
        "* Lock: Ensures that processes don’t interfere with each other when accessing shared resources.\n",
        "* Pool: Provides a convenient way to parallelize the execution of a function across multiple input values.\n",
        "\n",
        "# Why is Multiprocessing Useful?\n",
        "\n",
        "1. Efficient CPU Utilization: Python’s Global Interpreter Lock (GIL) limits the performance of CPU-bound tasks in multithreading. Multiprocessing overcomes this by creating separate memory spaces for each process, enabling true parallelism.\n",
        "\n",
        "2. Faster Execution of CPU-bound Tasks: For tasks that involve heavy computation, multiprocessing allows the program to utilize multiple CPU cores simultaneously, significantly reducing execution time.\n",
        "\n",
        "3. Isolated Processes: Since each process runs in its own memory space, there's no risk of data corruption between processes (unlike threads that share memory), making it easier to manage concurrent tasks.\n",
        "\n",
        "4. Parallelizing Independent Tasks: When you have tasks that are independent of each other, you can use multiprocessing to execute them concurrently, speeding up the overall runtime."
      ],
      "metadata": {
        "id": "gWR2WbRbNLBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. Differences between Multiprocessing and Multithreading\n",
        "\n",
        "Feature\t   Multiprocessing\t     Multithreading\n",
        "Definition\tInvolves running multiple processes (each with its own memory space).\tInvolves running multiple threads within the same process, sharing the same memory space.\n",
        "Memory\tEach process runs in its own memory space (separate).\tThreads share the same memory space within a process.\n",
        "Concurrency\tTrue parallelism (multiple processes run on different CPU cores).\tThreads run concurrently but not truly in parallel (due to Python’s GIL for CPU-bound tasks).\n",
        "Global Interpreter Lock (GIL)\tDoes not affect multiprocessing since each process has its own interpreter and memory space.\tAffected by GIL, which allows only one thread to execute Python bytecode at a time for CPU-bound tasks.\n",
        "CPU-bound tasks\tIdeal for CPU-bound tasks, like heavy computations, because it can fully utilize multiple CPU cores.\tNot effective for CPU-bound tasks due to GIL, which limits parallel execution.\n",
        "I/O-bound tasks\tCan be used for I/O-bound tasks, but usually overkill.\tMore suited for I/O-bound tasks (e.g., file reading, web scraping) because threads can switch while waiting for I/O operations to complete.\n",
        "Process Overhead\tProcesses are heavier, with more memory and time overhead for creating and managing them.\tThreads are lighter, with less overhead for creation and management.\n",
        "Fault Isolation\tFaults in one process don't affect other processes, as each process is independent.\tFaults in one thread can potentially crash the entire process since all threads share the same memory space.\n",
        "Use Cases\tBest for CPU-bound tasks (e.g., matrix multiplication, image processing, data crunching).\tBest for I/O-bound tasks (e.g., network requests, reading/writing files, web scraping).\n",
        "Communication Between Tasks\tRequires more complex inter-process communication mechanisms like Queues or Pipes.\tThreads can communicate more easily through shared variables (but this requires careful synchronization to avoid race conditions).\n",
        "Performance\tHigh performance for CPU-bound tasks when multiple cores are available.\tGood for tasks that rely on waiting for I/O, but limited for CPU-bound tasks due to GIL."
      ],
      "metadata": {
        "id": "fMfeIduvPyJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. Write a python code to create a process using the multiprocessing module.\n",
        "\n",
        "\n",
        "Here is a basic example of how to create a process using the multiprocessing module in Python:\n",
        "\n",
        "* Example Code: Creating a Process Using multiprocessing"
      ],
      "metadata": {
        "id": "H15L_wBIQqaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def worker_function():\n",
        "    \"\"\"This function will be run by the new process\"\"\"\n",
        "    print(\"Worker process is running\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a new process\n",
        "    process = multiprocessing.Process(target=worker_function)\n",
        "\n",
        "    # Start the process\n",
        "    process.start()\n",
        "\n",
        "    # Wait for the process to complete\n",
        "    process.join()\n",
        "\n",
        "    print(\"Main process is done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDtgnkodRC_q",
        "outputId": "3235f79f-ae34-442e-9469-bf5ccbebb470"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker process is running\n",
            "Main process is done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation:\n",
        "1. multiprocessing.Process(target=worker_function):\n",
        "\n",
        "* This creates a new process object. The target argument specifies the function that the new process will run (worker_function in this case).\n",
        "2. process.start():\n",
        "\n",
        "* Starts the process, which will execute the worker_function in a separate process.\n",
        "3. process.join():\n",
        "\n",
        "* This ensures that the main process waits for the newly started process to complete before proceeding."
      ],
      "metadata": {
        "id": "VAVhPP6YRIzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Q4. What is a multiprocessing pool in python? Why is it used?\n",
        "\n",
        "* A multiprocessing pool:-  in Python is a feature of the multiprocessing module that allows you to manage a group of worker processes. It provides a convenient way to parallelize the execution of a function across multiple input values. The pool creates a specified number of worker processes, which can execute tasks in parallel, making it easier to handle multiple tasks efficiently.\n",
        "\n",
        "# Key Features of Multiprocessing Pool:\n",
        "1. Worker Management: A pool manages a fixed number of worker processes, making it easy to distribute tasks among them without having to create and destroy processes manually.\n",
        "\n",
        "2. Task Distribution: The pool automatically distributes tasks to the available workers. When a worker is free, it picks up a new task, ensuring efficient use of resources.\n",
        "\n",
        "3. Ease of Use: It abstracts away the complexities of managing processes, making it simple to parallelize function execution.\n",
        "\n",
        "# Why is it Used?\n",
        "1. Efficiency: Using a pool of processes allows you to utilize multiple CPU cores effectively, improving performance for CPU-bound tasks.\n",
        "\n",
        "2. Resource Management: By limiting the number of active processes, you can avoid overloading the system and manage resource usage better compared to creating a new process for each task.\n",
        "\n",
        "3. Simplified Code: The Pool class simplifies code by providing methods like map(), apply(), and starmap(), allowing you to apply a function to a sequence of inputs easily.\n",
        "\n",
        "4. Better Performance for Large Tasks: When dealing with a large number of tasks, using a pool can result in better performance and reduced overhead than creating and destroying individual processes for each task."
      ],
      "metadata": {
        "id": "pzmD6RJZRfte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. How can we create a pool of worker processes in python using the multiprocessing module?\n",
        "\n",
        "You can create a pool of worker processes in Python using the multiprocessing module's Pool class. The Pool class allows you to manage multiple worker processes efficiently and parallelize the execution of a function across multiple inputs.\n",
        "\n",
        "#Steps to Create a Pool of Worker Processes\n",
        "1. Import the Module: Start by importing the multiprocessing module.\n",
        "2. Define the Worker Function: Create a function that you want to run in parallel.\n",
        "3. Create the Pool: Instantiate a Pool object specifying the number of worker processes.\n",
        "4. Distribute Tasks: Use methods like map(), apply(), or starmap() to distribute tasks among the worker processes.\n",
        "5. Close the Pool: Optionally, close the pool to prevent any more tasks from being submitted.\n",
        "6. Wait for Completion: Use join() to wait for all the worker processes to complete."
      ],
      "metadata": {
        "id": "Hb-6gpQgSVui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def worker_function(x):\n",
        "    \"\"\"Function to simulate work by sleeping and returning the square of x.\"\"\"\n",
        "    time.sleep(1)  # Simulating a time-consuming task\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a pool of worker processes\n",
        "    with multiprocessing.Pool(processes=4) as pool:\n",
        "        # Create a list of inputs for the worker function\n",
        "        inputs = list(range(10))\n",
        "\n",
        "        # Use the pool to compute the results in parallel\n",
        "        results = pool.map(worker_function, inputs)\n",
        "\n",
        "    print(\"Results:\", results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UxjGnLITAkA",
        "outputId": "5739d8ec-a960-4891-db8c-fb68e7131940"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q6. Write a python program to create 4 processes, each process should print a different number using the\n",
        "\n",
        "Here's a Python program that creates four processes using the multiprocessing module. Each process will print a different number:"
      ],
      "metadata": {
        "id": "or2so1odTTHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def print_number(number):\n",
        "    \"\"\"Function to print a number.\"\"\"\n",
        "    print(f\"Process {number}: {number}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # List of numbers to be printed by different processes\n",
        "    numbers = [1, 2, 3, 4]\n",
        "\n",
        "    # Create a list to hold the process objects\n",
        "    processes = []\n",
        "\n",
        "    # Create and start a process for each number\n",
        "    for number in numbers:\n",
        "        process = multiprocessing.Process(target=print_number, args=(number,))\n",
        "        processes.append(process)  # Add process to the list\n",
        "        process.start()  # Start the process\n",
        "\n",
        "    # Wait for all processes to complete\n",
        "    for process in processes:\n",
        "        process.join()\n",
        "\n",
        "    print(\"All processes have completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J87-V8KqTX5N",
        "outputId": "cc34cfb0-c708-4bc6-e96a-372c55c7233c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 2: 2Process 1: 1\n",
            "\n",
            "Process 3: 3\n",
            "Process 4: 4\n",
            "All processes have completed.\n"
          ]
        }
      ]
    }
  ]
}