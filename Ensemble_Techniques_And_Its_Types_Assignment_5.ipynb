{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwI0uclEB4Ku6VXVPvOUSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameermdanwer/python-assignment-/blob/main/Ensemble_Techniques_And_Its_Types_Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. You are working on a machine learning project where you have a dataset containing numerical and\n",
        "categorical features. You have identified that some of the features are highly correlated and there are\n",
        "missing values in some of the columns. You want to build a pipeline that automates the feature\n",
        "engineering process and handles the missing values.\n",
        "\n",
        "\n",
        "Building a machine learning pipeline to automate feature engineering and handle missing values can greatly streamline your workflow. Here’s a structured approach using Python's scikit-learn library, which allows you to create a clean and efficient pipeline.\n",
        "\n",
        "Step-by-Step Guide\n",
        "1. Import Necessary Libraries: You'll need pandas, numpy, and sklearn. Ensure you have these installed."
      ],
      "metadata": {
        "id": "T_7oKEdQmHk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n"
      ],
      "metadata": {
        "id": "PV3gLa1LmQJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load Your Dataset: Load your data into a pandas DataFrame."
      ],
      "metadata": {
        "id": "7ICtmM5PmSY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('your_dataset.csv')"
      ],
      "metadata": {
        "id": "5kcLdd7XmXYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Identify Numerical and Categorical Features: Specify which columns are numerical and which are categorical."
      ],
      "metadata": {
        "id": "Y2x7_x2Kma0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n"
      ],
      "metadata": {
        "id": "jP3Y9o2XmZ2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Handle Missing Values: Use SimpleImputer for numerical features (mean or median) and categorical features (most frequent).\n",
        "\n",
        "5. Create the Preprocessing Pipeline: Use ColumnTransformer to apply different transformations to different column types."
      ],
      "metadata": {
        "id": "hNpk4345mi3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),  # or 'median'\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "m7-VW40VmpJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Split the Data: Separate your target variable from your features and split the data into training and testing sets."
      ],
      "metadata": {
        "id": "BxO7WIG4mr2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('target_column', axis=1)  # Replace with your target column\n",
        "y = df['target_column']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "jG1so3z9mw_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Build the Full Pipeline: Include a machine learning model at the end of your pipeline. Here, we can use a Random Forest as an example."
      ],
      "metadata": {
        "id": "35VMBFD-m2RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  # or any other model\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier())\n",
        "])\n"
      ],
      "metadata": {
        "id": "W1sBWn4Km5cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Train the Model: Fit the model on the training data."
      ],
      "metadata": {
        "id": "NcXKTeX6m8cN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "nyoL04_HnBrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Evaluate the Model: Check the performance of your model using the test data."
      ],
      "metadata": {
        "id": "NVUBJJpYnHXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "zykWLzDlnKRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "This pipeline automates the process of handling missing values and scaling numerical features while encoding categorical variables. Adjust the imputer strategies and the model as needed for your specific dataset and objectives. You can also expand this pipeline to include additional feature engineering steps, such as polynomial feature generation or interaction terms, as required for your project.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MsW3aKgJnOCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gIIp5mVtnRuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then\n",
        "use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate  \n",
        "accuracy.\n",
        "\n",
        "To build a pipeline with both a Random Forest and Logistic Regression classifier, we can use a Voting Classifier from scikit-learn to combine their predictions. Here’s how to set it up and evaluate its accuracy on the Iris dataset.\n",
        "\n",
        "Steps\n",
        "1. Import Libraries: Import necessary libraries from scikit-learn.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dyqAUY2pnZI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "n6XT0fWgoG69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Load the Iris Dataset: Load the Iris dataset and split it into features (X) and target (y)."
      ],
      "metadata": {
        "id": "LxJrN3k3oJjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n"
      ],
      "metadata": {
        "id": "vgrvjASioNbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Split the Data: Split the data into training and testing sets."
      ],
      "metadata": {
        "id": "76TYJHvAoQ5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "mTJxrAUUoVwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Build the Classifier Pipelines: Define pipelines for both classifiers: Random Forest and Logistic Regression."
      ],
      "metadata": {
        "id": "cxQXZFdYoUfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pipeline = Pipeline([\n",
        "    ('rf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "lr_pipeline = Pipeline([\n",
        "    ('lr', LogisticRegression(max_iter=200, random_state=42))\n",
        "])\n"
      ],
      "metadata": {
        "id": "5Oiy57jgoeQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Combine Classifiers with a Voting Classifier: Use the VotingClassifier to combine the predictions of Random Forest and Logistic Regression. Set voting='soft' or voting='hard' depending on the voting strategy you want to use."
      ],
      "metadata": {
        "id": "ohXDiyRCocnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('rf', rf_pipeline), ('lr', lr_pipeline)],\n",
        "    voting='hard'  # or 'soft' for probabilistic voting\n",
        ")\n"
      ],
      "metadata": {
        "id": "SBAcm3vOojje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train the Voting Classifier: Fit the voting classifier on the training data."
      ],
      "metadata": {
        "id": "9yrRyUVlom2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voting_classifier.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "lqOHD9rGorvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluate the Model: Predict on the test set and calculate the accuracy."
      ],
      "metadata": {
        "id": "xoDHcycvoulX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = voting_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Voting Classifier Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "CdxcJ1VVoyp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Full code**"
      ],
      "metadata": {
        "id": "MrQcThAco0p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define classifier pipelines\n",
        "rf_pipeline = Pipeline([\n",
        "    ('rf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "lr_pipeline = Pipeline([\n",
        "    ('lr', LogisticRegression(max_iter=200, random_state=42))\n",
        "])\n",
        "\n",
        "# Combine classifiers with VotingClassifier\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[('rf', rf_pipeline), ('lr', lr_pipeline)],\n",
        "    voting='hard'  # use 'soft' if you want to use probabilities\n",
        ")\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = voting_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Voting Classifier Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "c8FVByhmo8mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y0gguuBepCpf"
      }
    }
  ]
}