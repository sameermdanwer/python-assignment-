{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjrZ0tTZhaPUi56N2JF3fS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameermdanwer/python-assignment-/blob/main/9th_April_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is Bayes' theorem?\n",
        "\n",
        "**Bayes' theorem** is a fundamental concept in probability theory and statistics that describes how to update the probability of a hypothesis based on new evidence. It provides a mathematical framework for updating beliefs in light of new information. The theorem is named after Thomas Bayes, an 18th-century statistician and theologian.\n",
        "\n",
        "**The Formula**\n",
        "\n",
        "Bayes' theorem is expressed mathematically as follows:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B)=\n",
        "P(B)\n",
        "P(Bâˆ£A)â‹…P(A)\n",
        "â€‹\n",
        "\n",
        "Where:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "* P(Aâˆ£B): The probability of event\n",
        "ğ´\n",
        "A occurring given that\n",
        "ğµ\n",
        "B is true (posterior probability).\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "* P(Bâˆ£A): The probability of event\n",
        "ğµ\n",
        "B occurring given that\n",
        "ğ´\n",
        "A is true (likelihood).\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "* P(A): The prior probability of event\n",
        "ğ´\n",
        "A occurring (prior).\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "* P(B): The total probability of event\n",
        "ğµ\n",
        "B occurring (marginal likelihood).\n",
        "Explanation of Components\n",
        "Prior Probability (\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "P(A)): This represents what is known about\n",
        "ğ´\n",
        "A before observing the evidence\n",
        "ğµ\n",
        "B.\n",
        "\n",
        "Likelihood (\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "P(Bâˆ£A)): This is the probability of observing the evidence\n",
        "ğµ\n",
        "B given that\n",
        "ğ´\n",
        "A is true. It measures how likely the evidence is if the hypothesis is correct.\n",
        "\n",
        "Marginal Likelihood (\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(B)): This is the total probability of observing the evidence\n",
        "ğµ\n",
        "B under all possible hypotheses. It can be calculated using the law of total probability:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "+\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "Â¬\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "Â¬\n",
        "ğ´\n",
        ")\n",
        "P(B)=P(Bâˆ£A)â‹…P(A)+P(Bâˆ£Â¬A)â‹…P(Â¬A)\n",
        "Posterior Probability (\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B)): This is the updated probability of\n",
        "ğ´\n",
        "A after taking into account the evidence\n",
        "ğµ\n",
        "B. It reflects how our belief in\n",
        "ğ´\n",
        "A has changed with the new evidence.\n",
        "**Applications of Bayes' Theorem**\n",
        "Bayes' theorem is widely used in various fields, including:\n",
        "\n",
        "* **Medical Diagnosis**: To update the probability of a disease based on test results.\n",
        "* **Machine Learning**: In algorithms like Naive Bayes classifiers for spam detection, text classification, etc.\n",
        "* **Finance**: For risk assessment and decision-making under uncertainty.\n",
        "* **Decision Making**: In situations involving uncertainty to revise probabilities as more information becomes available."
      ],
      "metadata": {
        "id": "BPQuqspAMmMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. What is the formula for Bayes' theorem?\n",
        "\n",
        "The **formula for Bayes' theorem** is expressed as:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B)=\n",
        "P(B)\n",
        "P(Bâˆ£A)â‹…P(A)\n",
        "â€‹\n",
        "\n",
        "**Breakdown of the Components:**\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "*  P(Aâˆ£B): The posterior probability of event\n",
        "ğ´\n",
        "A occurring given that event\n",
        "ğµ\n",
        "B is true.\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "* P(Bâˆ£A): The likelihood of event\n",
        "ğµ\n",
        "B occurring given that event\n",
        "ğ´\n",
        "A is true.\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "* P(A): The prior probability of event\n",
        "ğ´\n",
        "A occurring before considering event\n",
        "ğµ\n",
        "B.\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "* P(B): The marginal likelihood or total probability of event\n",
        "ğµ\n",
        "B occurring under all possible hypotheses.\n",
        "# Law of Total Probability\n",
        "To calculate\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(B), you can use the law of total probability:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "+\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "Â¬\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "Â¬\n",
        "ğ´\n",
        ")\n",
        "P(B)=P(Bâˆ£A)â‹…P(A)+P(Bâˆ£Â¬A)â‹…P(Â¬A)\n",
        "where\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "Â¬\n",
        "ğ´\n",
        ")\n",
        "P(Bâˆ£Â¬A) is the probability of\n",
        "ğµ\n",
        "B occurring given that\n",
        "ğ´\n",
        "A is not true, and\n",
        "ğ‘ƒ\n",
        "(\n",
        "Â¬\n",
        "ğ´\n",
        ")\n",
        "P(Â¬A) is the prior probability of\n",
        "ğ´\n",
        "A not occurring.\n",
        "\n"
      ],
      "metadata": {
        "id": "dCGczda9OEs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. How is Bayes' theorem used in practice?\n",
        "\n",
        "Bayes' theorem is widely applied across various fields to update beliefs, make predictions, and inform decisions based on new evidence. Here are some practical applications and examples of how Bayes' theorem is used:\n",
        "\n",
        "**1. Medical Diagnosis**\n",
        "\n",
        "Application: Doctors use Bayes' theorem to update the probability of a disease based on the results of diagnostic tests.\n",
        "Example: If a test for a disease has a known false positive and false negative rate, and the prior probability of the disease in the population is known, Bayes' theorem helps calculate the probability that a patient has the disease after receiving a positive test result.\n",
        "\n",
        "**2. Spam Detection**\n",
        "\n",
        "Application: Email services use Naive Bayes classifiers, which rely on Bayes' theorem, to classify emails as spam or not spam based on features like keywords.\n",
        "Example: By training the classifier on a labeled dataset of emails, it learns the likelihood of certain words appearing in spam versus non-spam emails, allowing it to update the probability of an incoming email being spam based on its content.\n",
        "\n",
        "**3. Machine Learning and AI**\n",
        "\n",
        "Application: Many machine learning algorithms, particularly in classification tasks, leverage Bayes' theorem.\n",
        "Example: In a predictive model, after training on historical data, Bayes' theorem can be used to update predictions as new data comes in, adjusting the model's confidence in its predictions.\n",
        "\n",
        "**4. Risk Assessment and Decision Making**\n",
        "\n",
        "Application: In finance, businesses use Bayes' theorem to assess risks and make investment decisions.\n",
        "Example: An investor might update the probability of a stock performing well based on new economic indicators, adjusting their investment strategy accordingly.\n",
        "\n",
        "**5. Weather Forecasting**\n",
        "\n",
        "Application: Meteorologists use Bayes' theorem to combine different sources of information to improve weather predictions.\n",
        "Example: If previous weather patterns suggest a certain likelihood of rain under specific conditions, Bayes' theorem can help update that probability based on current atmospheric data.\n",
        "\n",
        "**6. Legal Evidence Assessment**\n",
        "\n",
        "Application: In forensic science, Bayes' theorem is used to evaluate the strength of evidence in criminal cases.\n",
        "Example: If DNA evidence is found at a crime scene, Bayes' theorem can help determine the probability of a suspect being guilty given the presence of that evidence.\n",
        "\n",
        "**7. Marketing and Customer Behavior Analysis**\n",
        "\n",
        "Application: Companies analyze customer data to update their understanding of customer preferences and behaviors.\n",
        "Example: If a customer shows interest in a product category, Bayes' theorem can help predict the likelihood of that customer responding positively to targeted marketing for similar products."
      ],
      "metadata": {
        "id": "Q6zSXHcmOdQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
        "\n",
        "\n",
        "The relationship between Bayes' theorem and conditional probability is fundamental, as Bayes' theorem is essentially a formulation that expresses how to update probabilities based on conditional probabilities. Hereâ€™s how they are related:\n",
        "\n",
        "# 1. Understanding Conditional Probability\n",
        "**Conditional probability** is the probability of an event occurring given that another event has already occurred. It is denoted as:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ©\n",
        "ğµ\n",
        ")\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B)=\n",
        "P(B)\n",
        "P(Aâˆ©B)\n",
        "â€‹\n",
        "\n",
        "Where:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "* P(Aâˆ£B): The probability of event\n",
        "ğ´\n",
        "A given that event\n",
        "ğµ\n",
        "B has occurred (the conditional probability).\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ©\n",
        "ğµ\n",
        ")\n",
        "* P(Aâˆ©B): The joint probability of both events\n",
        "ğ´\n",
        "A and\n",
        "ğµ\n",
        "B occurring.\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "* P(B): The probability of event\n",
        "ğµ\n",
        "B occurring (must be greater than 0).\n",
        "# 2. Bayes' Theorem as a Formulation of Conditional Probability\n",
        "Bayes' theorem directly uses the concept of conditional probability to relate the probability of an event\n",
        "ğ´\n",
        "A given\n",
        "ğµ\n",
        "B to the probability of event\n",
        "ğµ\n",
        "B given\n",
        "ğ´\n",
        "A. It is expressed as:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B)=\n",
        "P(B)\n",
        "P(Bâˆ£A)â‹…P(A)\n",
        "â€‹\n",
        "\n",
        "This formulation shows how to compute the posterior probability\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "P(Aâˆ£B) using:\n",
        "\n",
        "* **The likelihood**\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "P(Bâˆ£A): The probability of observing evidence\n",
        "ğµ\n",
        "B assuming\n",
        "ğ´\n",
        "A is true.\n",
        "* The prior probability\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "P(A): The initial belief about\n",
        "ğ´\n",
        "A before observing\n",
        "ğµ\n",
        "B.\n",
        "* The marginal likelihood\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "P(B): The total probability of observing evidence\n",
        "ğµ\n",
        "B across all hypotheses.\n",
        "# 3. Key Takeaways\n",
        "* Update Beliefs: Bayes' theorem allows for the updating of beliefs about event\n",
        "ğ´\n",
        "A when new evidence\n",
        "ğµ\n",
        "B is observed, effectively using conditional probabilities.\n",
        "* Interchangeability: The theorem highlights the interchangeability of the events\n",
        "ğ´\n",
        "A and\n",
        "ğµ\n",
        "B through their conditional relationships, emphasizing that knowing\n",
        "ğµ\n",
        "B can provide valuable information about\n",
        "ğ´\n",
        "A and vice versa."
      ],
      "metadata": {
        "id": "Qhip2bQ-PVCH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
        "\n",
        "\n",
        "Choosing the appropriate type of Naive Bayes classifier depends on the nature of your data and the specific characteristics of the problem you are addressing. Here are the main types of Naive Bayes classifiers and guidance on when to use each:\n",
        "\n",
        "**Types of Naive Bayes Classifiers**\n",
        "1. Gaussian Naive Bayes\n",
        "\n",
        "* Description: Assumes that the features follow a Gaussian (normal) distribution.\n",
        "* Use Case: Suitable for continuous data that is normally distributed. It works well when the features have a bell-shaped distribution.\n",
        "* Example: Predicting class labels based on features such as heights, weights, or any other continuous measurement that is expected to follow a normal distribution.\n",
        "2. Multinomial Naive Bayes\n",
        "\n",
        "* Description: Specifically designed for discrete count data and is often used in text classification. It models the occurrence of each feature based on the multinomial distribution.\n",
        "* Use Case: Ideal for problems where the features represent frequencies or counts, such as word counts in document classification.\n",
        "* Example: Classifying emails as spam or not spam based on the frequency of words appearing in the emails.\n",
        "3. Bernoulli Naive Bayes\n",
        "\n",
        "* Description: Similar to Multinomial Naive Bayes but works with binary/boolean features. It models whether a feature is present or not, rather than how many times it appears.\n",
        "* Use Case: Suitable for binary feature data (0 or 1), such as presence or absence of words in text classification tasks.\n",
        "* Example: Classifying documents based on the presence or absence of specific keywords.\n",
        "# Factors to Consider When Choosing\n",
        "1.  Nature of Features:\n",
        "\n",
        "* If your features are continuous and assumed to follow a normal distribution, use Gaussian Naive Bayes.\n",
        "* If your features are discrete counts (e.g., word occurrences), use Multinomial Naive Bayes.\n",
        "* If your features are binary (presence/absence), opt for Bernoulli Naive Bayes.\n",
        "2. Data Distribution:\n",
        "\n",
        "* Analyze the distribution of your features. If they fit a normal distribution, Gaussian Naive Bayes is appropriate. If they donâ€™t, consider whether they are counts or binary.\n",
        "3. Dimensionality of Data:\n",
        "\n",
        "* If you have a high-dimensional feature space, such as in text classification, Multinomial Naive Bayes can handle this efficiently.\n",
        "4. Class Imbalance:\n",
        "\n",
        "* Consider how well each type performs with imbalanced classes. Experiment with different types to see which gives the best performance on your validation set.\n",
        "5. Performance Metrics:\n",
        "\n",
        "* Evaluate the performance of different classifiers using metrics like accuracy, precision, recall, and F1-score. You may need to experiment with multiple types of Naive Bayes classifiers to see which performs best for your specific dataset."
      ],
      "metadata": {
        "id": "NlHPmTHzQP-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qno 6 Assignment:\n",
        "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
        "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
        "each feature value for each class:\n",
        "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
        "A 3 3 4 4 3 3 3\n",
        "B 2 2 1 2 2 2 3\n",
        "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
        "to belong to?\n",
        "\n",
        "\n",
        "To predict the class of the new instance with features\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        "X1=3 and\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "X2=4 using Naive Bayes, we follow these steps:\n",
        "\n",
        "1. Calculate the likelihood of each class given the features.\n",
        "2. Use the prior probabilities (assumed equal in this case).\n",
        "3. Apply Bayes' theorem to calculate the posterior probabilities for each class.\n",
        "**Step 1: Calculate the Likelihoods**\n",
        "The likelihoods for class\n",
        "ğ´\n",
        "A and class\n",
        "ğµ\n",
        "B based on the frequency of feature values are:\n",
        "\n",
        "* For Class A:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "=\n",
        "FrequencyÂ of\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        "Â inÂ classÂ A\n",
        "TotalÂ inÂ classÂ A\n",
        "=\n",
        "4\n",
        "3\n",
        "+\n",
        "3\n",
        "+\n",
        "4\n",
        "=\n",
        "4\n",
        "10\n",
        "=\n",
        "0.4\n",
        "P(X1=3âˆ£A)=\n",
        "TotalÂ inÂ classÂ A\n",
        "FrequencyÂ ofÂ X1=3Â inÂ classÂ A\n",
        "â€‹\n",
        " =\n",
        "3+3+4\n",
        "4\n",
        "â€‹\n",
        " =\n",
        "10\n",
        "4\n",
        "â€‹\n",
        " =0.4\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "=\n",
        "FrequencyÂ of\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "Â inÂ classÂ A\n",
        "TotalÂ inÂ classÂ A\n",
        "=\n",
        "3\n",
        "10\n",
        "=\n",
        "0.3\n",
        "P(X2=4âˆ£A)=\n",
        "TotalÂ inÂ classÂ A\n",
        "FrequencyÂ ofÂ X2=4Â inÂ classÂ A\n",
        "â€‹\n",
        " =\n",
        "10\n",
        "3\n",
        "â€‹\n",
        " =0.3\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "=\n",
        "0.4\n",
        "â‹…\n",
        "0.3\n",
        "=\n",
        "0.12\n",
        "P(X1=3,X2=4âˆ£A)=P(X1=3âˆ£A)â‹…P(X2=4âˆ£A)=0.4â‹…0.3=0.12\n",
        "* For Class B:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "FrequencyÂ of\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        "Â inÂ classÂ B\n",
        "TotalÂ inÂ classÂ B\n",
        "=\n",
        "1\n",
        "2\n",
        "+\n",
        "2\n",
        "+\n",
        "1\n",
        "=\n",
        "1\n",
        "5\n",
        "=\n",
        "0.2\n",
        "P(X1=3âˆ£B)=\n",
        "TotalÂ inÂ classÂ B\n",
        "FrequencyÂ ofÂ X1=3Â inÂ classÂ B\n",
        "â€‹\n",
        " =\n",
        "2+2+1\n",
        "1\n",
        "â€‹\n",
        " =\n",
        "5\n",
        "1\n",
        "â€‹\n",
        " =0.2\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "FrequencyÂ of\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "Â inÂ classÂ B\n",
        "TotalÂ inÂ classÂ B\n",
        "=\n",
        "3\n",
        "5\n",
        "=\n",
        "0.6\n",
        "P(X2=4âˆ£B)=\n",
        "TotalÂ inÂ classÂ B\n",
        "FrequencyÂ ofÂ X2=4Â inÂ classÂ B\n",
        "â€‹\n",
        " =\n",
        "5\n",
        "3\n",
        "â€‹\n",
        " =0.6\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "0.2\n",
        "â‹…\n",
        "0.6\n",
        "=\n",
        "0.12\n",
        "P(X1=3,X2=4âˆ£B)=P(X1=3âˆ£B)â‹…P(X2=4âˆ£B)=0.2â‹…0.6=0.12\n",
        "**Step 2: Prior Probabilities**\n",
        "Assuming equal prior probabilities for both classes:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "0.5\n",
        "P(A)=P(B)=0.5\n",
        "**Step 3: Calculate Posterior** Probabilities\n",
        "Using Bayes' theorem:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "âˆ£\n",
        "ğ´\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        ")\n",
        "=\n",
        "0.12\n",
        "â‹…\n",
        "0.5\n",
        "=\n",
        "0.06\n",
        "P(Aâˆ£X1=3,X2=4)=P(X1=3,X2=4âˆ£A)â‹…P(A)=0.12â‹…0.5=0.06\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        ")\n",
        "=\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        "âˆ£\n",
        "ğµ\n",
        ")\n",
        "â‹…\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        ")\n",
        "=\n",
        "0.12\n",
        "â‹…\n",
        "0.5\n",
        "=\n",
        "0.06\n",
        "P(Bâˆ£X1=3,X2=4)=P(X1=3,X2=4âˆ£B)â‹…P(B)=0.12â‹…0.5=0.06\n",
        "**Step 4: Conclusion**\n",
        "Both posterior probabilities are equal:\n",
        "\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğ´\n",
        "âˆ£\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        ")\n",
        "=\n",
        "0.06\n",
        "P(Aâˆ£X1=3,X2=4)=0.06\n",
        "ğ‘ƒ\n",
        "(\n",
        "ğµ\n",
        "âˆ£\n",
        "ğ‘‹\n",
        "1\n",
        "=\n",
        "3\n",
        ",\n",
        "ğ‘‹\n",
        "2\n",
        "=\n",
        "4\n",
        ")\n",
        "=\n",
        "0.06\n",
        "P(Bâˆ£X1=3,X2=4)=0.06\n",
        "Since both classes\n",
        "ğ´\n",
        "A and\n",
        "ğµ\n",
        "B have equal probabilities for the given instance, Naive Bayes does not provide a clear preference for either class based on the data provided. In practice, a common approach in such cases is to choose the class that appeared first in the implementation or apply tie-breaking logic, but mathematically, they are equally likely based on this analysis.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VoZXz46JRWQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZDa9U7xfSnFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QmMKeD2UNwxV"
      }
    }
  ]
}